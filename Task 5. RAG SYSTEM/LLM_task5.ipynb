{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \\\n",
        "    qdrant-client \\\n",
        "    sentence-transformers \\\n",
        "    transformers \\\n",
        "    beautifulsoup4 \\\n",
        "    requests \\\n",
        "    tqdm \\\n",
        "    langchain \\\n",
        "    accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_PxXQCmNGZt",
        "outputId": "8eefbec3-a1f2-470b-bd6f-e69f9a82609c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/327.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m327.7/327.7 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.7/327.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/345.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.7/345.7 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.7/437.7 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from qdrant_client import QdrantClient, models\n",
        "from qdrant_client.http.models import PointStruct\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from typing import List, Dict, Tuple\n",
        "import time"
      ],
      "metadata": {
        "id": "xwyjtDIDNDFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_text(text: str, max_length: int = 512) -> List[str]:\n",
        "\n",
        "    paragraphs = text.split('\\n')\n",
        "    segments = []\n",
        "    current_segment = []\n",
        "    current_length = 0\n",
        "\n",
        "    for paragraph in paragraphs:\n",
        "        paragraph = paragraph.strip()\n",
        "        if not paragraph:\n",
        "            continue\n",
        "\n",
        "        if current_length + len(paragraph) + 1 <= max_length:\n",
        "            current_segment.append(paragraph)\n",
        "            current_length += len(paragraph) + 1\n",
        "        else:\n",
        "            if current_segment:\n",
        "                segments.append('\\n'.join(current_segment))\n",
        "                current_segment = [paragraph]\n",
        "                current_length = len(paragraph)\n",
        "            else:\n",
        "                segments.append(paragraph)\n",
        "                current_length = 0\n",
        "\n",
        "    if current_segment:\n",
        "        segments.append('\\n'.join(current_segment))\n",
        "\n",
        "    return segments"
      ],
      "metadata": {
        "id": "fa8GKekVOHEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовка сегментов для индексации\n",
        "def prepare_segments(data: Dict[str, str]) -> List[Dict]:\n",
        "    segments = []\n",
        "    segment_id = 0\n",
        "\n",
        "    for article_name, content in data.items():\n",
        "        article_segments = segment_text(content)\n",
        "\n",
        "        for i, segment in enumerate(article_segments):\n",
        "            segments.append({\n",
        "                \"id\": segment_id,\n",
        "                \"article\": article_name,\n",
        "                \"segment_num\": i,\n",
        "                \"text\": segment,\n",
        "                \"metadata\": {\n",
        "                    \"article\": article_name,\n",
        "                    \"segment\": i,\n",
        "                    \"total_segments\": len(article_segments)\n",
        "                }\n",
        "            })\n",
        "            segment_id += 1\n",
        "\n",
        "    return segments"
      ],
      "metadata": {
        "id": "5op7GYpVOI2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание базы данных Qdrant\n",
        "class VectorDatabase:\n",
        "    def __init__(self, collection_name: str = \"ml_handbook\", model_name: str = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"):\n",
        "        self.client = QdrantClient(\":memory:\")\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        self.collection_name = collection_name\n",
        "        self.dim = self.model.get_sentence_embedding_dimension()\n",
        "\n",
        "    def create_collection(self):\n",
        "        self.client.recreate_collection(\n",
        "            collection_name=self.collection_name,\n",
        "            vectors_config=models.VectorParams(\n",
        "                size=self.dim,\n",
        "                distance=models.Distance.COSINE\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def index_segments(self, segments: List[Dict]):\n",
        "        points = []\n",
        "\n",
        "        for segment in segments:\n",
        "            embedding = self.model.encode(segment[\"text\"]).tolist()\n",
        "\n",
        "            points.append(PointStruct(\n",
        "                id=segment[\"id\"],\n",
        "                vector=embedding,\n",
        "                payload={\n",
        "                    \"text\": segment[\"text\"],\n",
        "                    \"article\": segment[\"article\"],\n",
        "                    \"segment_num\": segment[\"segment_num\"],\n",
        "                    \"metadata\": segment[\"metadata\"]\n",
        "                }\n",
        "            ))\n",
        "\n",
        "        self.client.upsert(\n",
        "            collection_name=self.collection_name,\n",
        "            points=points\n",
        "        )\n",
        "\n",
        "    def search(self, query: str, top_k: int = 3) -> List[Dict]:\n",
        "        query_embedding = self.model.encode(query).tolist()\n",
        "\n",
        "        results = self.client.search(\n",
        "            collection_name=self.collection_name,\n",
        "            query_vector=query_embedding,\n",
        "            limit=top_k\n",
        "        )\n",
        "\n",
        "        return [{\n",
        "            \"score\": hit.score,\n",
        "            \"text\": hit.payload[\"text\"],\n",
        "            \"article\": hit.payload[\"article\"],\n",
        "            \"segment_num\": hit.payload[\"segment_num\"]\n",
        "        } for hit in results]"
      ],
      "metadata": {
        "id": "PJ4GybQtOPgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Модель для генерации ответов\n",
        "class TinyLlama:\n",
        "    def __init__(self, model_name: str = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"):\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "\n",
        "    def generate_answer(self, question: str, context: str = None, max_length: int = 512) -> str:\n",
        "        messages = []\n",
        "\n",
        "        if context:\n",
        "            messages.append({\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"Ты - помощник по машинному обучению. Отвечай на вопросы, используя предоставленный контекст:\\n{context}\"\n",
        "            })\n",
        "\n",
        "        messages.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": question\n",
        "        })\n",
        "\n",
        "        text = self.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "\n",
        "        model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        generated_ids = self.model.generate(\n",
        "            model_inputs.input_ids,\n",
        "            max_new_tokens=max_length,\n",
        "            pad_token_id=self.tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "        generated_ids = [\n",
        "            output_ids[len(input_ids):] for input_ids, output_ids in zip(\n",
        "                model_inputs.input_ids,\n",
        "                generated_ids\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "        return response.strip()"
      ],
      "metadata": {
        "id": "d2NHJyrDOSZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG система\n",
        "class RAGSystem:\n",
        "    def __init__(self):\n",
        "        self.vector_db = VectorDatabase()\n",
        "        self.llm = TinyLlama()\n",
        "        self.vector_db.create_collection()\n",
        "\n",
        "    def initialize(self, data_path: str):\n",
        "        with open(data_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        segments = prepare_segments(data)\n",
        "        self.vector_db.index_segments(segments)\n",
        "\n",
        "    # Поиск релевантных фрагментов\n",
        "    def answer_with_rag(self, question: str) -> Tuple[str, List[Dict]]:\n",
        "        search_results = self.vector_db.search(question)\n",
        "\n",
        "        context = \"\\n\\n\".join([res[\"text\"] for res in search_results])\n",
        "        answer = self.llm.generate_answer(question, context)\n",
        "\n",
        "        return answer, search_results\n",
        "\n",
        "    # Ответ без контекста\n",
        "    def answer_without_rag(self, question: str) -> str:\n",
        "        return self.llm.generate_answer(question)"
      ],
      "metadata": {
        "id": "MZ0-Ca8sOU1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag = RAGSystem()\n",
        "rag.initialize(\"handbook_articles.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT_ZtL7RPGc7",
        "outputId": "132d26d9-5dad-416b-a1dc-a2b4b3b1622b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:10: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
            "  self.client.recreate_collection(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №1: Что показывает ROC-кривая?\n"
      ],
      "metadata": {
        "id": "YfJKCxbyX4XH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = rag.answer_with_rag('Что показывает ROC-кривая?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Dttz0WOQxBl",
        "outputId": "1f47c2af-1aac-4021-8eb9-cb7bcd28d45e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGeRreieXqzg",
        "outputId": "80dfe5d6-8fbb-4ac8-90d7-8b77bbe7474c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.7177155737883694,\n",
              "  'text': 'Поэкспериментируйте с разными вариантами распределения предсказаний по классам и посмотрите, как меняется ROC-кривая.\\nЧем лучше классификатор разделяет два класса, тем больше площадь (area under curve) под ROC-кривой — и мы можем использовать её в качестве метрики. Эта метрика называетсяAUCи она работает благодаря следующему свойству ROC-кривой:\\nAUCравен доле пар объектов вида (объект класса 1, объект класса 0), которые алгоритм верно упорядочил, то есть предсказание классификатора на первом объекте больше:',\n",
              "  'article': 'Метрики классификации и регрессии',\n",
              "  'segment_num': 53},\n",
              " {'score': 0.6946442526940309,\n",
              "  'text': 'Если классификатор идеальный, — две кривые разделимы по оси X, — то на правом графике мы получаем ROC-кривую (0,0)->(0,1)->(1,1), площадь под которой равна 1.\\nЕсли классификатор случайный (предсказывает одинаковые метки положительным и отрицательным объектам), то мы получаем ROC-кривую (0,0)->(1,1), площадь под которой равна 0.5.\\nЕсли классификатор случайный (предсказывает одинаковые метки положительным и отрицательным объектам), то мы получаем ROC-кривую (0,0)->(1,1), площадь под которой равна 0.5.',\n",
              "  'article': 'Метрики классификации и регрессии',\n",
              "  'segment_num': 52},\n",
              " {'score': 0.5878783223280823,\n",
              "  'text': 'FPR(false positive rate) — это доля отрицательных объектов, неправильно предсказанных положительными:\\nОбе эти величины растут при уменьшении порога. Кривая в осях TPR/FPR, которая получается при варьировании порога, исторически называетсяROC-кривой(receiver operating characteristics curve, сокращённоROC curve). Следующийинтерактивный графикпоможет вам понять поведение ROC-кривой.',\n",
              "  'article': 'Метрики классификации и регрессии',\n",
              "  'segment_num': 50}]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "6skepd74W3BB",
        "outputId": "b6eb8c6f-5a16-4330-8c89-365f1ace8d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ROC-кривая (Receiver Operating Characteristic Curve, или кривая получения) представляет собой график, который показывает отношение плотности (распределения) предсказаний к плотности (распределения) объектов, которые были классифицированы правильно. ROC-кривая имеет две оси, X и Y, и имеет две линии, которые проходят через точки X и Y.\\n\\nПервая линия (X) проходит через точку Y, показывающую плотность объектов, которые были классифицированы правильно. Вторая линия (Y) проходит через точку X, показывающую плотность объектов, которые были классифицированы неправильно.\\n\\nОбъекты, которые были классифицированы правильно, имеют значение 1, а объекты, которые были классифицированы неправильно, имеют значение 0. ROC-кривая показывает, как плотность объектов, которые были классифицированы правильно, влияет на плотность объектов, которые были классифицированы неправильно.\\n\\nПри варьировании порога ROC-кривая меняется, показывая, как плотность объектов, которые были классифицированы правильно, влияет на плотность объектов, которые были классифицированы неправильно. Это позволяет определить, как правильно классифицировать объекты, и как можно улучшить классификатор.\\n\\nROC-кривая также используется в качестве метрики для оценки качества классификатора.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag.answer_without_rag('Что показывает ROC-кривая?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "6Ot93bavRVdk",
        "outputId": "81467af0-de77-4ebf-9c44-483ec7945c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ROC-кривая (Receiver Operating Characteristic Curve) описывает способность классификатора (например, классификатора решения задачи) набора признаков (например, признаков классификации) на определенных выборках (например, наборов данных) для определения оптимального значения параметра, который будет использоваться для классификации данных. ROC-кривая показывает, на каком протяжении распределения значений признаков распределение значений классифицируемых признаков соответствует распределению значений классифицируемых признаков на границе между классами. Если ROC-кривая имеет линейный ответ, то классификатор будет способен классифицировать данные на основе линейной функции распределения признаков. Если ROC-кривая имеет нелинейный ответ, то классификатор будет способен классифицировать данные на основе нелинейной функции распределения признаков. ROC-кривая также используется для оценки качества классификатора, который может быть использован для решения задач, в которых необходимо определить оптимальное значение параметра, который будет использоваться для классификации данных.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №2: Чем отличается L2 регуляризация от L1 регуляризации?"
      ],
      "metadata": {
        "id": "XZMaf0DbYHZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = rag.answer_with_rag('Чем отличается L2 регуляризация от L1 регуляризации?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym_4JA1yY-Gd",
        "outputId": "3c14a3fd-13b6-41dc-e9c7-96996e60b977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b1be89-4c03-4f95-cee8-41a7c50cffc4",
        "id": "OMDh_E5WY-NY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.5741340335616256,\n",
              "  'text': 'В параграфе «Регуляризация в онлайн-обучении» мы снова поговорим о регуляризации, но на этот раз речь пойдёт о регуляризаторах, которые накладывают на решение определённые органичения, например, разреженность. Вы сможете с новой стороны взглянуть на разреживающие свойства-регуляризаторов. Кроме того, мы получим не достижимые с помощью обычных SGD/AdaGrad результаты для разреженныхирегуляризаторов.',\n",
              "  'article': 'Введение в онлайн-обучение',\n",
              "  'segment_num': 9},\n",
              " {'score': 0.5729905223522018,\n",
              "  'text': 'Регуляризаторвыбирается так, чтобы выражениебыло 1-сильно выпукло по отношению к некоторой норме(возможно, своей на каждом шаге).\\nТогда\\nгде— норма, двойственная к норме.\\nПусть\\nОбновление параметров происходит по правилу\\nВыполнены все условия Setting 1;\\nВсе регуляризаторылежат в семействе FTRL-Proximal, причёмдля всех;\\nвыбирается так, чтобы выражениебыло 1-сильно выпукло по отношению к некоторой норме(возможно, своей на каждом шаге).\\nТогда\\nгде— норма, двойственная к норме.\\nПусть',\n",
              "  'article': 'Адаптивный FTRL',\n",
              "  'segment_num': 24},\n",
              " {'score': 0.5708723095888342,\n",
              "  'text': 'Слагаемое— это суммарная регуляризация в точке. Совсем избавиться от вхожденияне получится, но мы можем выбирать регуляризатор так, чтобы оценить сверхубыло не очень сложно.',\n",
              "  'article': 'Адаптивный FTRL',\n",
              "  'segment_num': 15}]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "8a339ad0-4f34-49a8-eefd-4c6a84b15042",
        "id": "pc96NQXfY-Na"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'L2 регуляризация и L1 регуляризация являются двух типов регуляризации в машинном обучении.\\n\\n1. L2 регуляризация:\\n\\nL2 регуляризация используется для регулирования векторов весов в модели, чтобы уменьшить размерность векторов. В L2 регуляризации вектор весов имеет максимальную длину, которая равна 1/2 * L2-norm( вектор весов).\\n\\n2. L1 регуляризация:\\n\\nL1 регуляризация используется для регулирования векторов весов, чтобы уменьшить их значение. В L1 регуляризации вектор весов имеет максимальную длину, которая равна 1/L1-norm( вектор весов).\\n\\nОбъяснение:\\n\\nВ L2 регуляризации вектор весов имеет максимальную длину, которая равна 1/2 * L2-norm( вектор весов). Это означает, что если вектор весов имеет длину 1, то его максимальная длина равна 1/2 * L2-norm( вектор весов). В L1 регуляризации вектор весов имеет максимальную длину, которая равна 1/L1-norm( вектор весов). Это означает, что если вектор весов имеет длину 1, то его максимальная длина равна 1/L1-norm( вектор весов).\\n\\nВ результате, L2 регуляризация позволяет уменьшить размерность векторов весов, а L1 регуляризация позволяет уменьшить их значение.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag.answer_without_rag('Чем отличается L2 регуляризация от L1 регуляризации?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "832bac9a-3191-4745-ddbb-50eb9925a5ad",
        "id": "0hE_TJFYY-Nb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'L2 регуляризация (L2 Regularization) и L1 регуляризация (L1 Regularization) отличаются в том, что L2 регуляризация использует векторную функцию, а L1 регуляризация использует векторную функцию с весом, который равен 1.0.\\n\\nL2 регуляризация используется для уменьшения разницы между весами и весами, которые были обучены на тестовых данных. Это позволяет обученным весам уменьшить разницу между весами, которые были обучены на тестовых данных и весами, которые были обучены на обучающей выборке.\\n\\nL1 регуляризация используется для уменьшения разницы между весами, которые были обучены на тестовых данных и весами, которые были обучены на обучающей выборке. Это позволяет обученным весам уменьшить разницу между весами, которые были обучены на тестовых данных и весами, которые были обучены на обучающей выборке.\\n\\nОбщие сведения о L2 регуляризации:\\n- В L2 регуляризации векторная функция используется для уменьшения разницы между весами, которые были обучены на тестовых данных и весами, которые были обучены на обучающей выборке.\\n- В L1 регуляризации векторная функция используется для уменьшения разницы между весами, которые были обучены на тестовых данных и весами, которые были обучены на обучающей выборке.\\n- В L2 регуляризации векторная функция имеет вес 1.0, а в L1 регуляризации векторная функция имеет вес 1.0.\\n\\nОбщие сведения о L1 регуляризации:\\n- В L1 регуляризации векторная функция используется для уменьшения разницы между весами, которые были обучен'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №3: Что такое функция потерь?"
      ],
      "metadata": {
        "id": "Y22N4byNaSCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = rag.answer_with_rag('Что такое функция потерь?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aaa21b9-cfa9-4af7-ebc6-fdcc1a2fb392",
        "id": "ifeh7EkQaBMd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e139d36-9608-42a6-909f-ebbe7c2a8799",
        "id": "vkhtbW4MaBMf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.6863597437137183,\n",
              "  'text': 'Функция потерь возникает в тот момент, когда мы сводим задачу построения модели к задаче оптимизации. Обычно требуется, чтобы она обладала хорошими свойствами (например, дифференцируемостью).\\nФункция потерь возникает в тот момент, когда мы сводим задачу построения модели к задаче оптимизации. Обычно требуется, чтобы она обладала хорошими свойствами (например, дифференцируемостью).\\nМетрика — внешний, объективный критерий качества, обычно зависящий не от параметров модели, а только от предсказанных меток.',\n",
              "  'article': 'Метрики классификации и регрессии',\n",
              "  'segment_num': 11},\n",
              " {'score': 0.6532116755668944,\n",
              "  'text': 'В случае квадратичной функции потерь интуиция вполне подкрепляется математикой. Изменится ли что-либо в наших действиях, если мы поменяем квадратичную функцию потерь на любую другую? С одной стороны, мы, как и прежде, можем двигаться в направлении уменьшения разности предсказания и истинного значения: любая функция потерь поощряет такие шаги для каждого отдельного объекта, ведь для любой адекватной функции потерь выполнено.',\n",
              "  'article': 'Градиентный бустинг',\n",
              "  'segment_num': 22},\n",
              " {'score': 0.6435091750214192,\n",
              "  'text': 'Отметим, что- и-регуляризацию можно определять для любой функции потерь(и не только в задаче регрессии, а и, например, в задаче классификации тоже). Новая функция потерь будет соответственно равна\\nили\\nРазреживание весов в-регуляризации\\n========================================',\n",
              "  'article': 'Линейные модели',\n",
              "  'segment_num': 82}]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "9f89d67e-beee-44b6-d863-0450274a5a0e",
        "id": "elVNl14maBMg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Функция потерь (loss function) в математической оптимизации является функцией, которая определяет качество решения задачи. В случае регрессии функция потерь может быть определена как функция от отклонения предсказанных значений от значений исходных данных. В случае классификации функция потерь может быть определена как функция от отклонения предсказанных классов от значений исходных классов.\\n\\nФункция потерь используется в качестве метрики качества в задачах регрессии и классификации. В регрессии функция потерь определяет качество решения задачи, а в классификации функция потерь определяет качество решения задачи.\\n\\nВ математической оптимизации функция потерь используется для определения оптимального решения задачи. В случае регрессии функция потерь используется для определения оптимального значения параметра, а в классификации функция потерь используется для определения оптимального класса.\\n\\nФункция потерь также используется в других областях, таких как оптимизация, а также в других сферах, таких как искусственный интеллект и компьютерное программирование.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag.answer_without_rag('Что такое функция потерь?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "76be8d12-0256-483d-ac27-819ec3451c6d",
        "id": "M5u820ieaBMi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Функция потерь (loss function) - это функция, которая определяет качество или качество, которое требуется достичь в процессе обучения модели. В математическом смысле, функция потерь представляет собой функцию, которая определяет качество или качество, которое требуется достичь в процессе обучения модели. В языке программирования, функция потерь используется для определения качества модели, которая должна быть хорошо обучена.\\n\\nФункция потерь может быть различной в зависимости от задачи, которая используется для обучения модели. Например, в регрессии, функция потерь может быть функцией суммы квадратов ошибок (MSE), функцией суммы квадратов ошибок (MAE), функцией суммы квадратов ошибок (RMSE), функцией суммы квадратов ошибок (MSE), функцией суммы квадратов ошибок (MAPE), функцией суммы квадратов ошибок (RMSE), функцией суммы квадратов ошибок (MAPE), функцией суммы квадратов ошибок (RMSE), функцией суммы квадратов ошибок (MAPE), функцией суммы квадратов ошибок (RMSE), функцией суммы квадратов ошибок (MAPE), функцией суммы квадратов ошибок (RMSE), функцией суммы квадратов ошибок (MAPE), функцией суммы квадратов ошибок (RMSE), функцией суммы квадратов ошибок (MAPE), функцией суммы квадратов ошибок (RMSE), функцией суммы квадратов ошибок (MAPE), функцией суммы квадратов ошибок (RMSE), функцией суммы квадратов ошибок (MAPE), функцией суммы квадратов ошибок (RMSE), функцией су'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KPDygASla5Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №4: Чем отличается бустинг от бэггинга?"
      ],
      "metadata": {
        "id": "MJcTGkBfa84C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = rag.answer_with_rag('В чем разница между бэггингом и бустингом?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c18b0f3f-508c-48b3-ff2e-2339414c5968",
        "id": "wADCdWLSa84E"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5be07672-59a7-4041-8345-9252df41d93e",
        "id": "BlxLMNGZa84G"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.5538680788056545,\n",
              "  'text': 'Рассмотрим две моды с силамии, такие что. Насколько вторая (более слабая) мода выучится к моменту, когда первая уже выучится на долю? Из уравнения выше имеем:\\nПодставляяи, получаем:\\nПоскольку, это выражение стремится к минус бесконечности при, из чего следует, чтостремится к нулю.',\n",
              "  'article': 'Implicit bias',\n",
              "  'segment_num': 9},\n",
              " {'score': 0.5021280466152587,\n",
              "  'text': 'Состояние игрока — это сложное понятие, но, вероятно, мы можем выразить его, зная пульс, давление и другие физические показатели. В свою очередь, ситуацию на поле можно описать, как функцию от позиций и движений других игроков, судьи и зрителей — но всего не перечислишь, поэтому нам снова придётся привлекать случайность. Таким образом, мы получаем то, что называетсяграфической моделью:',\n",
              "  'article': 'Вероятностный подход в ML',\n",
              "  'segment_num': 16},\n",
              " {'score': 0.4990544110693901,\n",
              "  'text': 'Heavy-ball Momentum: используется для ускорения процесса оптимизации. В выпуклых задачах имеет доказанные оценки на улучшение скорости сходимости, в нейросетях используется как эвристика (зачастую опциональная).\\nNesterov momentum: в выпуклом случае гораздо мощнее для batch gradient descent, чем обычный momentum, и это подверждается теоретическими гарантиями. В стохастических методах оптимизации и в онлайн обучении «в лоб» применять нельзя: для выпуклого случая подойдет Katyusha, для нейросетей — Adan.',\n",
              "  'article': 'Методы оптимизации в Deep Learning',\n",
              "  'segment_num': 82}]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "585e64f6-8e0c-4b97-863d-e5b21036a149",
        "id": "H_iu07xva84I"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Бэггинг и бустингом (Bagging и Boosting) являются двух основных методами в стохастической оптимизации.\\n\\n1. Бэггинг:\\nБэггинг (Bagging) - это метод, который использует несколько экземпляров (всего N) кластеров для обучения. В каждом кластере обучается только один экземпляр, а затем эти экземпляры используются для обучения остальных кластеров. Этот метод используется для улучшения скорости сходимости и уменьшения размерности выборки.\\n\\n2. Бустингом:\\nБустингом (Boosting) - это метод, который использует несколько экземпляров (всего N) кластеров для обучения. В каждом кластере обучается только один экземпляр, а затем эти экземпляры используются для обучения остальных кластеров. Этот метод используется для улучшения скорости сходимости и уменьшения размерности выборки.\\n\\nВажное отличие между этими методами заключается в том, что в бустинге используется несколько экземпляров кластеров, а не один. Это позволяет уменьшить размерность выборки, что в свою очередь позволяет улучшить скорость сходимости.\\n\\nВажное отличие между этими методами заключается в том, что в бустинге используется несколько экземпляров кластеров, а не один. Это позволяет уменьшить размерность выборки, что в свою очередь позволяет улучшить скорость сходимости.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag.answer_without_rag('В чем разница между бэггингом и бустингом?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "4f20690c-471e-45c9-f9a8-9f75cc4a9b0f",
        "id": "2Tir8BYEa84M"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Бэггингом и бустингом относятся к разным методам тестирования программного обеспечения.\\n\\n1. Бэггинг: это метод тестирования, в котором программный код тестируется в режиме реального времени, то есть он выполняется в среде разработки. Этот метод позволяет определить, какие части программы работают нормально и какие нет.\\n\\n2. Бустинг: это метод тестирования, в котором программный код тестируется в режиме отладки, то есть он выполняется в среде отладки. Этот метод позволяет определить, какие части программы работают нормально и какие нет.\\n\\nОбщая разница между этими методами заключается в том, что бэггинг позволяет определить, какие части программы работают нормально и какие нет, то есть он позволяет тестировать программный код в режиме реального времени. Бустинг, в свою очередь, позволяет определить, какие части программы работают нормально и какие нет, то есть он позволяет тестировать программный код в режиме отладки.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №5: Что такое LogLoss и зачем используется?"
      ],
      "metadata": {
        "id": "jgKggRC7dQ2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = rag.answer_with_rag('Что такое логарифмическая функция потерь и зачем используется?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19f9712f-eab5-4809-8b95-872ef6c507a5",
        "id": "cxVEsEejdQ29"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbe312fb-a538-432b-cb92-211d57d16b1c",
        "id": "q1PNHkytdQ3C"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.6244355807364056,\n",
              "  'text': 'Модель обучается на стандартную функцию потерь (например, LogLoss).\\nИспользуя вещественные предсказания на валидационной выборке, перебирая разные пороги от 0 до 1, получаем графики метрик в зависимости от порога.\\nВыбираем нужное сочетание точности и полноты.',\n",
              "  'article': 'Метрики классификации и регрессии',\n",
              "  'segment_num': 73},\n",
              " {'score': 0.6106060670086974,\n",
              "  'text': 'Регуляризационный член не зависит от выборки и добавляется отдельно:\\nСоответственно, идеальный градиент регуляризованной функции потерь имеет вид\\nГрадиент по батчу – это тоже оценка градиента идеальной функции потерь, только не на выборке, а на батчеразмера. Он будет выглядеть так:',\n",
              "  'article': 'Линейные модели',\n",
              "  'segment_num': 79},\n",
              " {'score': 0.6040932804460828,\n",
              "  'text': 'Бинарную классификацию рекомендовать/не рекомендовать. Тогдаимеет смысл логита, и мы можем оптимизировать оптимизировать log loss или hinge loss.\\nРанжирование объектов. Тогда– это ранжирующая функция.\\nМодель обычно обучается градиентным спуском.\\nFFM – Field-aware Factorization Machines\\n========================================\\nОригинальная статья\\nСтатья про практическое применение',\n",
              "  'article': 'Контентные рекомендации',\n",
              "  'segment_num': 9}]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "4e517478-edf6-4007-a586-3202ae5c78ae",
        "id": "jh47YHucdQ3D"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Логарифмическая функция потерь (LogLoss) используется в моделировании и оптимизации алгоритмов для решения задач машинного обучения.\\n\\nОна представляет собой функцию, которая оценивает качество модели на выборке, используя значение функции потерь на базовой выборке. Логарифмическая функция потерь используется для оценки качества модели, учитывая различия в размере выборки и размерности векторов входных данных.\\n\\nВыборка, используемая для оценки качества модели, называется базовой выборкой. Логарифмическая функция потерь используется для оценки качества модели на этой выборке.\\n\\nОсновная причина использования логарифмической функции потерь в моделировании и оптимизации алгоритмов для решения задач машинного обучения заключается в том, что она позволяет определить, насколько хорошо модель работает на данной выборке, и если она работает хорошо, то она может быть использована для обучения модели на других выборках.\\n\\nОднако, в некоторых случаях, когда базовая выборка не является достаточно разнообразной, логарифмическая функция потерь может быть недостаточно эффективной для оценки качества модели. В таких случаях, в качестве базовой выборки могут использоваться выборки с более высоким уровнем разнообразия, чтобы уменьшить размерность векторов входных данных.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag.answer_without_rag('Что такое логарифмическая функция потерь и зачем используется?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "af84e1d8-ad63-4134-b44d-499f6f1072cf",
        "id": "d6Bo14f6dQ3F"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Логарифмическая функция потерь (Laplace's function of loss)  является функцией, которая определяет потерю в случае, когда потерь неизвестна. В данном случае, потерь можно определить как функцию потерь, которая принимает в качестве аргумента значение потерь, а затем вычисляет потерю в случае, когда потерь неизвестна.\\n\\nВ примере, когда потерь неизвестна, функция потерь используется для определения потерь в случае, когда потерь неизвестна. В данном случае, функция потерь используется для определения потерь в случае, когда потерь неизвестна.\\n\\nПример:\\n\\nДаны следующие данные:\\n\\n- Потерь в случае, когда потерь неизвестна: 10\\n- Потерь в случае, когда потерь известна: 15\\n\\n- Потерь, которая принимает значение 10 в случае, когда потерь неизвестна: 10\\n- Потерь, которая принимает значение 15 в случае, когда потерь известна: 15\\n\\nВ результате, функция потерь определяет потерю в случае, когда потерь неизвестна.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №6: Как работают свёрточные нейронные сети??"
      ],
      "metadata": {
        "id": "97NIEe4teVac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = rag.answer_with_rag('Объясни, как работают свёрточные нейронные сети?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66468952-f658-4faf-e57b-07d7d9a59ac8",
        "id": "OaGAcTgUeVak"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d95cf63-31bd-4acd-f7c7-05745e4c15c2",
        "id": "OMLJq11ueVao"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.7812052110251886,\n",
              "  'text': 'Основные определения\\n========================================\\nИскусственная нейронная сеть (далее — нейронная сеть)— это сложная дифференцируемая функция, задающая отображение из исходного признакового пространства в пространство ответов, все параметры которой могут настраиваться одновременно и взаимосвязанно (то есть сеть может обучаться end-to-end).\\nВ частном (и наиболее частом) случае представляет собой последовательность дифференцируемых параметрических преобразований.',\n",
              "  'article': 'Первое знакомство с полносвязными нейросетями',\n",
              "  'segment_num': 0},\n",
              " {'score': 0.7505699426525361,\n",
              "  'text': 'В качестве иллюстрации ниже приведены структуры агностических нейронных сетей WANN, представленных в работеWeight Agnostic Neural Networks, NeurIPS 2019.\\nForward & backward propagation\\n========================================\\nИнформация может течь по графу в двух направлениях.',\n",
              "  'article': 'Первое знакомство с полносвязными нейросетями',\n",
              "  'segment_num': 13},\n",
              " {'score': 0.7459735535048715,\n",
              "  'text': '========================================\\nКак вы уже успели заметить, нейронные сети — достаточно сложные модели, чувствительные к изменениям архитектуры, гиперпараметров, распределения данных и другим вещам.\\nПоэтому значительную роль играет начальная инициализация весов вашей сети. Стоит отметить, что здесь речь идет именно о начальной инициализации параметров сети, вопрос дообучения (и использования предобученных сетей в качестве backbone) в данном параграфе рассматриваться не будет.',\n",
              "  'article': 'Тонкости обучения',\n",
              "  'segment_num': 1}]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "385da8b9-1b5e-419b-ed82-8e13ef670839",
        "id": "igQ8EgcleVaq"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Свёрточные нейронные сети (SqueezeNet, ResNet, etc.) - это семейство нейронных сетей, основанных на свёрточных слоях. В свёрточных слоях используются слои с малым числом входных и выходных каналов, но большим числом входных и выходных узлов. Это позволяет снизить размерность изображения, что в свою очередь позволяет снизить размерность выходных данных.\\n\\nВ свёрточных нейронных сетах используются следующие схемы свёрточных слоев:\\n\\n1. Squeeze-and-Excitation (SE) - это схема свёрточных слоев, в которой каждый слой свёртывает входную матрицу, а затем вычисляет вектор смещения, который используется для вычисления векторов смещения для следующего слоя.\\n\\n2. Pointwise Convolution (PC) - это схема свёрточных слоев, в которой каждый слой производит конvolution с малым числом входных каналов и вычисляет вектор смещения.\\n\\n3. Squeeze-and-Attention (SA) - это схема свёрточных слоев, в которой каждый слой свёртывает входную матрицу, а затем вычисляет вектор смещения, который используется для вычисления векторов смещения для следующего слоя.\\n\\n4. Squeeze-and-Excitation (SE) + Pointwise Convolution (PC) - это схема свёрточных слоев, в которой каждый слой свёртывает входную матрицу, а затем вычисляет вектор смещения, который используется для вычисления векторов смещения для следующего слоя.\\n\\nВсе эти схемы свёрточных слоев позволяют снизить размерность выходных данных, что в свою очередь позволяет снизить размер'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag.answer_without_rag('Объясни, как работают свёрточные нейронные сети?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "c4ba7b05-a68f-41bc-da61-75e8dbf655e5",
        "id": "xBPKwzU7eVat"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Свёрточные нейронные сети (SqueezeNet) - это один из наиболее популярных свёрточных нейронных сетей, разработанных в 2016 году. В свёрточных нейронных сетах используется смесь свёрточных и несвёрточных нейронов, которые работают в смеси сверху и снизу.\\n\\nСвёрточные нейроны - это нейроны, которые имеют сверху и снизу входные и выходные каналы, но не имеют входных и выходных каналов внутри себя. Это позволяет снизить размерность входных и выходных каналов, что в свою очередь позволяет снизить размерность выходных данных.\\n\\nВ свёрточных нейронных сетах используется смесь сверху и снизу свёрточных нейронов. В сверху свёрточные нейроны работают с входными и выходными каналами, которые разделены на две части. Входные каналы соединены свёрточными нейронами, которые обрабатывают данные внутри себя. Выходные каналы соединены свёрточными нейронами, которые обрабатывают данные внутри себя.\\n\\nВ свёрточных нейронных сетах используется смесь сверху и снизу свёрточных нейронов, что позволяет снизить размерность входных и выходных каналов. Это позволяет снизить размерность выходных данных, что в свою очередь позволяет снизить размерность выходных данных.\\n\\nВ свёрточных нейронных сетах используется смесь сверху и снизу свёрточных нейронов, что позволяет снизить размерность входных и выходных каналов. Это позволяет снизить размерность выходных данных, что в свою очередь позволяет снизить размерность вы'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №7: Как работает механизм внимания?"
      ],
      "metadata": {
        "id": "PAhFd9kUheGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = rag.answer_with_rag('Как работает механизм внимания?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf76e7e2-3443-449c-f2b2-94cc2b1ed2a0",
        "id": "HeJ5HMcmheG6"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3fbdf9f-3c56-418d-add2-4daa40705e5f",
        "id": "P7j_P95VheG-"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.7865614502891869,\n",
              "  'text': 'Механизм внимания(attention) реализует эту интуицию путем предоставления декодеру информации обо всех токенах исходного предложения на каждом шаге генерации. Рассмотрим классическую модель внимания, предложенную Bahdanau et al. в 2014 году.',\n",
              "  'article': 'Нейросети для работы с последовательностями',\n",
              "  'segment_num': 72},\n",
              " {'score': 0.7378263160129224,\n",
              "  'text': 'Механизм внутреннего внимания(self-attention) используется, чтобы посмотреть на другие слова во входной последовательности во время кодирования конкретного слова. Изначально этот механизм был представлен встатьеAttention is all you need как элемент архитектуры «трансформер» (Transformer).',\n",
              "  'article': 'Нейросети для работы с последовательностями',\n",
              "  'segment_num': 77},\n",
              " {'score': 0.712755813560159,\n",
              "  'text': 'Существует много разных видов механизмов внимания, например:\\nБазовый dot-product, рассмотренный ранее:\\nМультипликативный:, где— обучаемая матрица весов.\\nMLP:, где,— обучаемые матрицы весов,— обучаемый вектор весов\\nВажной особенностью механизма внимания является то, что его веса несут в себе информацию о связях слов в двух языках, участвующих в переводе. Визуализировав веса механизма внимания, получаем таблицу взаимосвязей между словами:',\n",
              "  'article': 'Нейросети для работы с последовательностями',\n",
              "  'segment_num': 75}]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "ca0efd55-50b1-4c90-b11d-170bb6c594cf",
        "id": "tfEMtC2mheHB"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'В механизме внимания (Attention) используется предоставление декодеру информации обо всех токенах исходного предложения на каждом шаге генерации. Этот механизм реализуется путем предоставления декодеру информации обо всех токенах исходного предложения на каждом шаге генерации.\\n\\nДекодер получает вход из входной последовательности, которая состоит из двух частей:\\n\\n1. Входной последовательность (Input sequence) - это входная последовательность, которая состоит из двух частей:\\n\\n- Входной слова (Input word) - это каждый из слова в исходном предложении.\\n- Входной вектор (Input vector) - это вектор с весами, которые используются для обучения механизма внимания.\\n\\n2. Декодер получает входную последовательность и вектор входных данных.\\n\\nДекодер использует предоставленный контекст для получения информации о связях между словами в двух языках, участвующих в переводе.\\n\\nВесь процесс генерации заключается в том, чтобы декодер получал входную последовательность и вектор входных данных, а затем использовал предоставленный контекст для получения информации о связях между словами в двух языках, участвующих в переводе.\\n\\nВ результате получается входная последовательность, которая состоит из двух частей:\\n\\n1. Входной слова (Input word) - это каждый из слова в исходном предложении.\\n2. Входной вектор (Input vector) - это вектор с весами, которые используются для обучения механизма внимания.\\n\\nВ результате получается входная последовательность, которая состоит из двух частей:\\n\\n1. Входной слова (Input word) - каждый из слова в исходном предложении.\\n2. Входной вектор (Input vector) - вектор с весами,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag.answer_without_rag('Как работает механизм внимания?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "f3089dd9-d12e-43ba-b200-97fd812a33d9",
        "id": "konRPgoyheHD"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The mechanism of attention is a complex process that involves the brain's frontal lobes, which are responsible for regulating and controlling attention. Attention is a critical cognitive function that allows us to focus our attention on specific tasks or objects, and it is essential for our daily lives.\\n\\nThe mechanism of attention works by detecting and processing information that is relevant to our current task or goal. When we encounter a stimulus that is relevant to our attention, our frontal lobes activate, and we focus our attention on that stimulus. This process is called selective attention.\\n\\nOnce we have focused our attention on a stimulus, our frontal lobes continue to monitor the stimulus and adjust our attention as needed. For example, if we are reading a book and come across a sentence that is relevant to our current task, our frontal lobes will activate and focus our attention on that sentence. If we are interrupted by a phone call or a distracting noise, our frontal lobes will adjust our attention to the task at hand.\\n\\nThe mechanism of attention is a complex process that involves multiple brain regions and neural networks. It is influenced by a variety of factors, including our prior experience with the stimulus, our emotional state, and our current task. Overall, the mechanism of attention is a critical component of our cognitive function and plays a crucial role in our ability to focus our attention and perform tasks effectively.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №7: Объясни принцип работы случайного леса"
      ],
      "metadata": {
        "id": "R4lutqgfiTkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = rag.answer_with_rag('Объясни принцип работы случайного леса')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f422b3cc-adbe-466e-9d99-f11468217fb0",
        "id": "Yo_2-UG7iTks"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9376868-4970-46a5-8941-cc6f2dca076c",
        "id": "oJ3KnJe1iTkw"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.7303675852727778,\n",
              "  'text': 'Чтобы получить предсказание ансамбля на тестовом объекте, усредняем отдельные ответы деревьев (для регрессии) или берём самый популярный класс (для классификации).\\nProfit. Мы построилиRandom Forest (случайный лес)— комбинацию бэггинга и метода случайных подпространств над решающими деревьями.\\nProfit. Мы построилиRandom Forest (случайный лес)— комбинацию бэггинга и метода случайных подпространств над решающими деревьями.',\n",
              "  'article': 'Ансамбли в машинном обучении',\n",
              "  'segment_num': 18},\n",
              " {'score': 0.7001641233160569,\n",
              "  'text': 'Вторым практическим ограничением на количество деревьев может быть время работы ансамбля. Однако есть положительное свойство случайного леса: случайный лес можно строить и применять параллельно, что сокращает время работы, если у нас есть несколько процессоров. Но процессоров, скорее всего, всё же сильно меньше числа деревьев, а сами деревья обычно глубокие. Поэтому на большом числе деревьев Random Forest может работать дольше желаемого и количество деревьев можно сократить, немного пожертвовав качеством.',\n",
              "  'article': 'Ансамбли в машинном обучении',\n",
              "  'segment_num': 25},\n",
              " {'score': 0.6908440446833963,\n",
              "  'text': 'Внимательный читатель мог заметить, что при построении случайного леса у специалиста по машинному обучению есть несколько степеней свободы. Давайте обсудим их подробнее.\\nКакая должна быть глубина деревьев в случайном лесу?\\n========================================',\n",
              "  'article': 'Ансамбли в машинном обучении',\n",
              "  'segment_num': 19}]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "f3e592ab-bc66-4936-9614-810188a11a62",
        "id": "zFxyAWhdiTky"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Всем привет! В этом ответе расскажу, как работает случайный лес в машинном обучении.\\n\\nСлучайный лес - это алгоритм, который используется для построения регрессии или классификации. Он основан на идее, что в случае, когда в данных есть много признаков, то можно использовать только несколько из них для построения модели.\\n\\nДля построения случайного леса используется метод случайных подпространств над решающими деревьями. Этот метод позволяет построить случайный лес, который будет содержать только несколько деревьев, но будет иметь высокую точность и скорость работы.\\n\\nВ качестве решающего дерева случайный лес использует случайные подпространства, которые являются подпространствами решающего дерева. В качестве подпространства случайный лес использует случайные подпространства, которые являются подпространствами решающего дерева.\\n\\nВ качестве решающего дерева случайный лес использует случайные подпространства, которые являются подпространствами решающего дерева. В качестве подпространства случайный лес использует случайные подпространства, которые являются подпространствами решающего дерева.\\n\\nВ качестве решающего дерева случайный лес использует случайные подпространства, которые являются подпространствами решающего дерева. В качестве подпространства случайный лес использует случайные подпространства, которые являются подпространствами решающего дерева.\\n\\nВ качестве решающего дерева случайный лес использует случайные подпространства, которые являются подпространствами решающего дерева. В качестве подпространства случайный лес использует случайные подпространства, которые являются подпространствами решающего дерева.\\n\\nВ качестве решающего дерева случайный лес использует случайные подпространства, которые являются подпространствами решающего дерева. В качестве подпространства слу'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag.answer_without_rag('Объясни принцип работы случайного леса')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "1377c0fc-7da6-4c5b-c877-9797fa51baca",
        "id": "wXFzCRKCiTk1"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Суть принципа работы случайного леса заключается в том, что в нём происходит неопределенное сочетание различных элементов, которые взаимодействуют друг с другом в определённой последовательности. В случае случайного леса эти элементы могут быть разными по типу, размеру, цвету, расположению и\\xa0т.\\xa0д.\\n\\nПринцип работы случайного леса основан на том, что в нём происходит неопределенное сочетание различных элементов, которые взаимодействуют друг с другом в определённой последовательности. В случае случайного леса эти элементы могут быть разными по типу, размеру, цвету, расположению и\\xa0т.\\xa0д.\\n\\nОбъяснение принципа работы случайного леса можно найти в книге \"Суперпозиция и случайный лес\" (англ. \"Superposition and Random Forest\") автора Джона К. Смита. В ней автор рассматривает случайный лес как упрощённый вариант суперпозиции, которая также является методом классификации данных.\\n\\nВ суперпозиции элементы могут быть разными по типу, размеру, цвету, расположению и\\xa0т.\\xa0д. В случае случайного леса элементы могут быть разными по типу, размеру, цвету, расположению и\\xa0т.\\xa0д.\\n\\nВ суперпозиции элементы могут быть разными по типу, размеру, цвету, расположению и\\xa0т.\\xa0д. В случае случайного леса элементы могут быть разными по типу, размеру, цвету, расположению и\\xa0т.\\xa0д.\\n\\nОбъяснение принципа работы случайного леса можно найти в книге \"Суперпозиция и случайный лес\" (англ. \"Superposition and Random Forest\") автора Джона К. Смита. В ней автор рассматривает случай'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №8"
      ],
      "metadata": {
        "id": "_zCfY75ejvH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = 'Что такое градиентный бустинг?'\n",
        "answer = rag.answer_with_rag(question)\n",
        "print(f\"\\n\\nВопрос: {question}\\n\\n\")\n",
        "print(f\"Информация из векторной базы данных: {answer[1]}\\n\\n\")\n",
        "print(f\"Ответ модели с RAG: {answer[0]}\\n\\n\")\n",
        "print(f\"Ответ модели без RAG: {rag.answer_without_rag(question)}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3iKom_kkkk4",
        "outputId": "97ef09db-fc6a-4d10-f37b-feb39dab9c7b"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Вопрос: Что такое градиентный бустинг?\n",
            "\n",
            "\n",
            "Информация из векторной базы данных: [{'score': 0.580110389938626, 'text': 'где– это дисперсия стохградиента, а– константа сильной выпуклости, показывающая, насколько функция является «не плоской» в окрестности точки оптимума. Доказательство в том жепрепринте С. Стича.\\nМораль в следующем: дисперсия стохастического градиента, вычисленного по батчу размераравна, где– это дисперсия одного градиента. То есть увеличение размера батча помогает и с теоретической точки зрения.', 'article': 'Оптимизация в ML', 'segment_num': 39}, {'score': 0.5784129723220435, 'text': 'Для объяснения метода градиентного бустинга полезно воспользоваться следующей аналогией. Бустинг можно представить как гольфиста, цель которого — загнать мяч в лунку с координатой. Положение мяча здесь – ответ композиции. Гольфист мог бы один раз ударить по мячу, не попасть в лунку и пойти домой, но настырность заставляет его продолжить.', 'article': 'Градиентный бустинг', 'segment_num': 9}, {'score': 0.5756845750734427, 'text': 'Таким образом, найдётсятакое, что для любыхсуществует паратакая, что градиентный спуск, примененный к, стартующий ви действующий только на, сходится в точку.', 'article': 'Ландшафт функции потерь', 'segment_num': 10}]\n",
            "\n",
            "\n",
            "Ответ модели с RAG: Gradiantn buistng (GB) или градиентный бустинг (GB) - это метод оптимизации, который используется для решения задач, в которых необходимо найти максимальное значение функции, которая является функцией от некоторого параметра. В GB функция является дифференцируемой функцией, которая имеет вид:\n",
            "\n",
            "f(x) = f(x1) + f(x2) + ... + f(xn)\n",
            "\n",
            "где f(x) - это функция от x, а x1, x2, ..., xn - параметры. В GB функция f(x) является дифференцируемой, т.е. Ее производная f'(x) существует. В GB функция f(x) является дисперсией, т.е. Ее дисперсия - это функция от x, которая определяет, насколько функция f(x) изменяется при изменении параметра x. В GB функция f(x) является неплоской, т.е. Ее константа сильной выпуклости - это функция от x, которая определяет, насколько функция f(x) изменяется при изменении параметра x. В GB функция f(x) является неплоской, т.е. Ее константа сильной выпуклости - это функция от x, которая определяет, насколько функция f(x) изменяется при изменении параметра x. В GB функция f(x) является неплоской, т.е. Ее константа сильной выпуклости - это функция от x, которая определяет, насколько функция f(x) изменяется при изменении параметра x. В GB функция f(x) является неплоской, т.е. Ее константа сильной выпуклости - это функция от x, которая определяет, насколько функция f(x) изменяется при изменении параметра x. В GB функция f(x) является неплоской, т.е. Ее константа сильной выпуклости - это функция от x, которая определяет, насколько функция\n",
            "\n",
            "\n",
            "Ответ модели без RAG: Gradianty buisting (GB) es un algoritmo de regresión lineal que utiliza un modelo de regresión lineal para estimar la función de regresión lineal para un conjunto de datos. El modelo de regresión lineal es un modelo lineal que predice la variable de respuesta a partir de la variable de entrada. El GB es un algoritmo de regresión lineal que utiliza un modelo de regresión lineal para estimar la función de regresión lineal para un conjunto de datos. El GB utiliza un modelo de regresión lineal para estimar la función de regresión lineal para un conjunto de datos. El GB es un algoritmo de regresión lineal que utiliza un modelo de regresión lineal para estimar la función de regresión lineal para un conjunto de datos. El GB utiliza un modelo de regresión lineal para estimar la función de regresión lineal para un conjunto de datos. El GB es un algoritmo de regresión lineal que utiliza un modelo de regresión lineal para estimar la función de regresión lineal para un conjunto de datos. El GB utiliza un modelo de regresión lineal para estimar la función de regresión lineal para un conjunto de datos. El GB es un algoritmo de regresión lineal que utiliza un modelo de regresión lineal para estimar la función de regresión lineal para un conjunto de datos. El GB utiliza un modelo de regresión lineal para estimar la función de regresión lineal para un conjunto de datos. El GB es un algoritmo de regresión lineal que utiliza un modelo de regresión lineal para estimar la función de regresión lineal para un conjunto de datos. El GB utiliza un modelo de regresión lineal para estimar la función de regresión lineal para un conjunto de datos. El GB es un algoritmo de regresión lineal que utiliza un modelo de regresión lineal para estimar la función de regresión lineal para un conjunto de datos. El GB utiliza un modelo de regresión lineal para estimar la función de regresión lineal para un conjunto de datos. El GB es un algoritmo de regresión lineal que utiliza un modelo de regresión lineal para estimar la\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №9"
      ],
      "metadata": {
        "id": "FLc2LGAynFmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Чем XGBoost отличается от LightGBM?\"\n",
        "answer = rag.answer_with_rag(question)\n",
        "print(f\"\\n\\nВопрос: {question}\\n\\n\")\n",
        "print(f\"Информация из векторной базы данных: {answer[1]}\\n\\n\")\n",
        "print(f\"Ответ модели с RAG: {answer[0]}\\n\\n\")\n",
        "print(f\"Ответ модели без RAG: {rag.answer_without_rag(question)}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIe9X5zvnRAo",
        "outputId": "b85f060c-fec8-476e-e8e7-36f94bcd5d0b"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Вопрос: Чем XGBoost отличается от LightGBM?\n",
            "\n",
            "\n",
            "Информация из векторной базы данных: [{'score': 0.6915209880402512, 'text': 'Хороших реализаций GBDT есть, как минимум, три:LightGBM,XGBoostиCatBoost. Исторически они отличались довольно сильно, но за последние годы успели скопировать друг у друга все хорошие идеи.\\nОдно из основных отличий LightGBM, XGBoost и CatBoost — форма решающих деревьев.', 'article': 'Градиентный бустинг', 'segment_num': 47}, {'score': 0.6061749739187492, 'text': 'С одной стороны, это позволяет быстро подогнаться под обучающие данные. С другой — бесконтрольный рост дерева в глубину неизбежно ведет к переобучению, поэтому LightGBM позволяет помимо количества вершин ограничивать и максимальную глубину. Впрочем, это ограничение обычно все равно выше, чем для XGBoost и CatBoost.', 'article': 'Градиентный бустинг', 'segment_num': 49}, {'score': 0.49852047327580534, 'text': 'Это один из важнейших компонент всвёрточныхнейронных сетях. Веса свёртки, упорядоченные в тензор (в нашем случае размерностиHxWx3), составляют еёядро. Область картинки, которая обрабатывается в текущий момент, обычно называетсяокном свёртки.\\n```HxWx3```\\nОбратите внимание, что обычно такие свёртки называются двумерными — так как окно свёртки пробегает по двум измерениям картинки (при этом все цветовые каналы участвуют в вычислениях).', 'article': 'Свёрточные нейросети', 'segment_num': 12}]\n",
            "\n",
            "\n",
            "Ответ модели с RAG: XGBoost и LightGBM являются двух основных алгоритмами для машинного обучения, которые используют решающие деревья для решения задач классификации и регрессии. Однако существует некоторая разница между ними.\n",
            "\n",
            "XGBoost является одним из самых популярных алгоритмов для машинного обучения, основанным на решающих деревьях. Он был разработан в 2015 году и является одним из самых быстрых алгоритмов для решения задач классификации и регрессии. XGBoost использует решающие деревья, которые могут быть построены на основе множества деревьев, и он использует гиперпараметры, которые можно изменить для оптимизации.\n",
            "\n",
            "LightGBM также является одним из самых популярных алгоритмов для машинного обучения, основанным на решающих деревьях. Он был разработан в 2015 году и является одним из самых быстрых алгоритмов для решения задач классификации и регрессии. LightGBM также использует решающие деревья, но он использует гиперпараметры, которые можно изменить для оптимизации.\n",
            "\n",
            "Однако существует некоторая разница между XGBoost и LightGBM. XGBoost использует гиперпараметры, которые можно изменить для оптимизации, но он также использует решающие деревья, которые могут быть построены на основе множества деревьев. LightGBM, напротив, использует гиперпараметры, которые можно изменить для оптимизации, но он также использует решающие деревья, которые могут быть построены на основе множества деревьев.\n",
            "\n",
            "Однако, в целом, XGBoost и LightGBM являются двух основных алгоритмами для машинного обучения, которые используют решающие деревья для решения задач классификации и регрессии.\n",
            "\n",
            "\n",
            "Ответ модели без RAG: XGBoost and LightGBM are two popular machine learning algorithms for building decision trees. Here are some key differences between the two:\n",
            "\n",
            "1. Training: XGBoost is a gradient boosting algorithm, while LightGBM is a gradient boosting method. Gradient boosting is a technique used in machine learning to improve the accuracy of decision trees by adding multiple decision trees to the model.\n",
            "\n",
            "2. Feature selection: XGBoost uses a feature selection technique called \"bagging\" to select the best features for the decision tree. LightGBM uses a feature selection technique called \"bagging\" and \"boosting\" to select the best features for the decision tree.\n",
            "\n",
            "3. Hyperparameter tuning: XGBoost uses a grid search technique to find the optimal hyperparameters for the decision tree. LightGBM uses a grid search and a random search technique to find the optimal hyperparameters for the decision tree.\n",
            "\n",
            "4. Performance: XGBoost has been shown to perform better than LightGBM in many real-world applications. However, both algorithms have their strengths and weaknesses, and the choice between them depends on the specific use case and the available data.\n",
            "\n",
            "5. Scalability: XGBoost is designed to handle large datasets, while LightGBM is more suitable for smaller datasets. However, both algorithms can handle large datasets with appropriate tuning.\n",
            "\n",
            "Overall, XGBoost and LightGBM are both powerful and effective machine learning algorithms for building decision trees. The choice between them depends on the specific use case and the available data.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №10"
      ],
      "metadata": {
        "id": "VYxXdJRonUVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Как работает метод опорных векторов?\"\n",
        "answer = rag.answer_with_rag(question)\n",
        "print(f\"\\n\\nВопрос: {question}\\n\\n\")\n",
        "print(f\"Информация из векторной базы данных: {answer[1]}\\n\\n\")\n",
        "print(f\"Ответ модели с RAG: {answer[0]}\\n\\n\")\n",
        "print(f\"Ответ модели без RAG: {rag.answer_without_rag(question)}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1N60JvbnUVG",
        "outputId": "79e5700d-92b1-4d28-d2ba-f3e921ccff60"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Вопрос: Как работает метод опорных векторов?\n",
            "\n",
            "\n",
            "Информация из векторной базы данных: [{'score': 0.7394976401360729, 'text': 'Итоговое положение плоскости задаётся всего несколькими обучающими примерами. Это ближайшие к плоскости правильно классифицированные объекты, которые называютопорными векторамиилиsupport vectors. Весь метод, соответственно, зовётся методомопорных векторов, илиsupport vector machine, или сокращённоSVM. Начиная с шестидесятых годов это был сильнейший из известных методов машинного обучения. В девяностые его сменили методы, основанные на деревьях решений, которые, в свою очередь, недавно передали «пальму первенства» нейросетям.', 'article': 'Линейные модели', 'segment_num': 109}, {'score': 0.7019017736401407, 'text': 'Представим себе самую простую модель, основанную на данном принципе — что-то вроде ансамбля линейных. Каждую из сдвинутых картинок вытянем в вектор и скалярно умножим на вектор весов (для простоты один и тот же для всех сдвигов) — получим линейный оператор, для которого есть специальное имя —свёртка.', 'article': 'Свёрточные нейросети', 'segment_num': 11}, {'score': 0.6884735519321452, 'text': 'Модель 3. Метод опорных векторов.\\nДавайте построим еще один классификатор на основе линейного метода опорных векторов.\\nВажно: Не забудьте привести признаки к единому масштабу, иначе численный алгоритм не сойдется к решению и мы получим гораздо более плохо работающее решающее правило. Попробуйте проделать это упражнение.', 'article': 'Метрики классификации и регрессии', 'segment_num': 28}]\n",
            "\n",
            "\n",
            "Ответ модели с RAG: The method of support vectors (SVM) is a machine learning algorithm that is used for classification and regression tasks. It works by finding a set of hyperplanes that separate the data points into two classes. The algorithm starts by defining a set of hyperplanes, which are linear functions that can be used to separate the data points into two classes.\n",
            "\n",
            "The algorithm then finds the support vectors, which are the points in the hyperplane that are closest to the decision boundary. These support vectors are used to calculate the weights of the hyperplanes, which are used to calculate the coefficients of the linear function.\n",
            "\n",
            "The algorithm then calculates the distance between each data point and the decision boundary, and uses this distance to assign each data point to one of the two classes. The algorithm then repeats this process for all the data points, and the final classification result is the class that has the smallest distance to the decision boundary.\n",
            "\n",
            "The method of support vectors is a non-linear algorithm, which means that it does not use a linear function to separate the data points. Instead, it uses a set of hyperplanes that are linear functions, which can be used to separate the data points into two classes. This makes the method of support vectors more flexible and adaptable to different data sets.\n",
            "\n",
            "\n",
            "Ответ модели без RAG: The method of orthogonal projection (or principal component analysis, PCA) is a statistical technique used to reduce the dimensionality of a high-dimensional data set by projecting it onto a set of linearly independent vectors called principal components. The method works by finding the eigenvectors of a covariance matrix, which is a matrix that measures the similarity between observations. The eigenvectors are the linearly independent vectors that maximize the variance of the data.\n",
            "\n",
            "The method of orthogonal projection is based on the principle that the projection of a vector onto a linearly independent set of vectors is the same as the projection of the vector onto the orthogonal complement of the set. This means that the projection of a vector onto a set of orthogonal vectors is the same as the projection of the vector onto the orthogonal complement of the set.\n",
            "\n",
            "The method of orthogonal projection is a non-linear algorithm that requires a pre-processing step to select the principal components. The pre-processing step involves selecting the principal components that maximize the variance of the data. The selected principal components are then used to project the data onto the selected principal components.\n",
            "\n",
            "The method of orthogonal projection is widely used in various fields, including data analysis, machine learning, and signal processing. It is particularly useful in high-dimensional data analysis, where the number of observations is large and the data is not linearly separable. The method of orthogonal projection can also be used to reduce the dimensionality of high-dimensional data without losing much information.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №11"
      ],
      "metadata": {
        "id": "zuW2H35tnUjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Что такое TF-IDF и как он применяется в NLP? \"\n",
        "answer = rag.answer_with_rag(question)\n",
        "print(f\"\\n\\nВопрос: {question}\\n\\n\")\n",
        "print(f\"Информация из векторной базы данных: {answer[1]}\\n\\n\")\n",
        "print(f\"Ответ модели с RAG: {answer[0]}\\n\\n\")\n",
        "print(f\"Ответ модели без RAG: {rag.answer_without_rag(question)}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRcK9xIEnUjC",
        "outputId": "c7c202f5-b1d1-4ea5-9af9-c4b35a001829"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Вопрос: Что такое TF-IDF и как он применяется в NLP? \n",
            "\n",
            "\n",
            "Информация из векторной базы данных: [{'score': 0.42880618730996956, 'text': 'Значение классификаторов\\nМногие модели могут подстроиться под эти факторы и отдельно обучиться под различные значения запросных признаков. Например, так модель может по-разному реагировать на запросы из разных стран.\\nЧтобы сопоставить запрос и документ, можно использовать TF-IDF слов запроса. Например, можно просуммировать его по всем словам из запроса и получить фактор для ранжирования. Подробно о том, как считать TF-IDF, можно прочитать в главе про NLP.', 'article': 'Задача ранжирования', 'segment_num': 61}, {'score': 0.36777754896963255, 'text': 'SFT (supervised finetuning) — обучение модели следовать инструкциям. Этот пункт мы подробно обсудили в предыдущей части параграфа (T0, FLAN, CoT). На этом этапе важно составить грамотный инструкционный датасет, где инструкция содержит произвольные запросы к модели, а ответ на неё — подробный текст, которым будущий пользователь будет доволен. Грамотный сбор таких данных довольно дорогостоящий процесс, но от него напрямую зависит, каким образом модель будет взаимодействовать с пользователем.', 'article': 'Языковые модели', 'segment_num': 48}, {'score': 0.3544315194731824, 'text': 'FPR(false positive rate) — это доля отрицательных объектов, неправильно предсказанных положительными:\\nОбе эти величины растут при уменьшении порога. Кривая в осях TPR/FPR, которая получается при варьировании порога, исторически называетсяROC-кривой(receiver operating characteristics curve, сокращённоROC curve). Следующийинтерактивный графикпоможет вам понять поведение ROC-кривой.', 'article': 'Метрики классификации и регрессии', 'segment_num': 50}]\n",
            "\n",
            "\n",
            "Ответ модели с RAG: TF-IDF (Term Frequency - Inverse Document Frequency) - это метод оценки вероятности использования слова в тексте. Он используется в NLP (Natural Language Processing) для оценки вероятности того, что определенный словосъёмник (term) встретится в тексте.\n",
            "\n",
            "Основная идея TF-IDF заключается в том, что частота встречаемости слова в тексте (term frequency) может быть больше, чем частота его использования в документах (inverse document frequency, idf). Это означает, что частота встречаемости слова в тексте может быть больше, чем частота его использования в документах, что может быть связано с тем, что документы, в которых встречается термин, не являются документами, в которых он встречается часто.\n",
            "\n",
            "TF-IDF используется в NLP для оценки вероятности того, что определенный словосъёмник (term) встретится в тексте. Это означает, что для определения вероятности использования слова в тексте, необходимо учитывать, что частота встречаемости слова в тексте может быть больше, чем частота его использования в документах.\n",
            "\n",
            "Пример использования TF-IDF в NLP:\n",
            "\n",
            "1. В тексте \"The quick brown fox jumps over the lazy dog\" частота встречаемости слова \"jumps\" (term frequency) составляет 2, частота его использования в документах (idf) составляет 1.\n",
            "\n",
            "2. В тексте \"The quick brown fox jumps over the lazy dog\" частота встречаемости слова \"dog\" (term frequency) составляет 1, частота его использования в документах (idf) составляет 1.\n",
            "\n",
            "3. В тексте \"The quick brown fox jumps over the lazy dog\" частота встречаемости слова \"lazy\" (term frequency) составляет 1, частота его использования в документах (idf) составляет 1.\n",
            "\n",
            "4. В тексте \"The quick brown fox jumps over the lazy dog\" частота встречаемости слова \"jumps\n",
            "\n",
            "\n",
            "Ответ модели без RAG: TF-IDF (Term Frequency - Inverse Document Frequency) es una técnica de representación de texto utilizada en la NLP (Natural Language Processing).\n",
            "\n",
            "En términos generales, TF-IDF es una técnica de representación de texto que se basa en la frecuencia de cada palabra en un texto y su relación con otras palabras en el mismo texto. La frecuencia de una palabra en un texto es la cantidad de veces que aparece en ese texto, mientras que la frecuencia de una palabra en otro texto es la cantidad de veces que aparece en el mismo texto pero en otro lugar.\n",
            "\n",
            "En NLP, TF-IDF se utiliza para predecir la probabilidad de que una palabra aparezca en un texto dado. Por ejemplo, si un modelo de NLP pretende predecir si una palabra aparecerá en un texto, TF-IDF le ayudará a calcular la probabilidad de que aparezca en el texto.\n",
            "\n",
            "En NLP, TF-IDF se utiliza para predecir la probabilidad de que una palabra aparezca en un texto dado. Por ejemplo, si un modelo de NLP pretende predecir si una palabra aparecerá en un texto, TF-IDF le ayudará a calcular la probabilidad de que aparezca en el texto.\n",
            "\n",
            "En NLP, TF-IDF se utiliza para predecir la probabilidad de que una palabra aparezca en un texto dado. Por ejemplo, si un modelo de NLP pretende predecir si una palabra aparecerá en un texto, TF-IDF le ayudará a calcular la probabilidad de que aparezca en el texto.\n",
            "\n",
            "En NLP, TF-IDF se utiliza para predecir la probabilidad de que una palabra aparezca en un texto dado. Por ejemplo, si un modelo de NLP pretende predecir si una palabra aparecerá en un texto, TF-IDF le ayudará a calcular la probabilidad de que aparezca en el texto.\n",
            "\n",
            "En NLP,\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №12"
      ],
      "metadata": {
        "id": "1N2EB87VnUxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Что такое кросс-валидация?\"\n",
        "answer = rag.answer_with_rag(question)\n",
        "print(f\"\\n\\nВопрос: {question}\\n\\n\")\n",
        "print(f\"Информация из векторной базы данных: {answer[1]}\\n\\n\")\n",
        "print(f\"Ответ модели с RAG: {answer[0]}\\n\\n\")\n",
        "print(f\"Ответ модели без RAG: {rag.answer_without_rag(question)}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8NNfxeAnUxf",
        "outputId": "78dbc004-7b41-419d-a278-53d9ffb1d973"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Вопрос: Что такое кросс-валидация?\n",
            "\n",
            "\n",
            "Информация из векторной базы данных: [{'score': 0.7646141532130247, 'text': 'Кросс-валидация — это процедура для оценки качества работы модели, которая широко применяется в машинном обучении. Она помогает сравнить между собой различные модели и выбрать наилучшую для конкретной задачи.\\nВ этом разделе мы рассмотрим наиболее распространённые методы кросс-валидации, а также обсудим возможные проблемы, которые могут возникнуть в процессе их применения.\\nHold-out\\n========================================\\nМетодhold-outпредставляет из себя простое разделение на train и test:', 'article': 'Кросс-валидация', 'segment_num': 0}, {'score': 0.6591472369690808, 'text': 'В sklearn реализована такая схема кросс-валидации:', 'article': 'Кросс-валидация', 'segment_num': 42}, {'score': 0.45562286854676354, 'text': 'Финальный скор модели получается либо усреднениемполучившихся тестовых результатов, либо измеряется на отложенном тестовом множестве, не участвовавшем в кросс-валидации.\\nЭтот метод есть в sklearn:', 'article': 'Кросс-валидация', 'segment_num': 25}]\n",
            "\n",
            "\n",
            "Ответ модели с RAG: Кросс-валидация (cross-validation) — это процедура для оценки качества работы модели, которая широко применяется в машинном обучении. Она помогает сравнивать между собой различные модели и выбрать наилучшую для конкретной задачи.\n",
            "\n",
            "Кросс-валидация разделяет наtrain и test, где train — это обучающая выборка, и test — это тестовый выборк, не участвовавший в обучении.\n",
            "\n",
            "В процессе кросс-валидации используется разделение на train и test, и каждый раз, когда модель будет использована для обучения, она будет пройти кросс-валидацию.\n",
            "\n",
            "Примеры кросс-валидации:\n",
            "\n",
            "1. K-fold cross-validation: используется для оценки качества модели на разных подмножествах обучающей выборки.\n",
            "\n",
            "2. Stratified cross-validation: используется для оценки качества модели на подмножестве обучающей выборки, где размер обучающей выборки не равен размеру обучающей выборки.\n",
            "\n",
            "3. Grid search: используется для оценки качества модели на разных параметрах.\n",
            "\n",
            "4. Randomized cross-validation: используется для оценки качества модели на разных подмножествах обучающей выборки, используя случайные подмножества обучающей выборки.\n",
            "\n",
            "5. Bayesian cross-validation: используется для оценки качества модели на разных подмножествах обучающей выборки, используя Bayesian методы.\n",
            "\n",
            "6. Leave-one-out cross-validation: используется для оценки качества модели на разных подмножествах обучающей выборки, используя разные подмножества обучающей выборки.\n",
            "\n",
            "7. Leave-one-out cross-validation with stratified sampling: используется для оценки качества модели на разных подмножествах обучающей выборки, используя разные подмножества\n",
            "\n",
            "\n",
            "Ответ модели без RAG: Кросс-валидация (англ. Cross-validation) — это метод проверки качества модели на данных, разделенных на две части: тестовой и тренировочной. В данном случае, например, для модели регрессии, кросс-валидация позволяет проверить, насколько правильно модель работает на тестовой выборке, а не на тренировочной.\n",
            "\n",
            "Кросс-валидация используется в моделировании данных, когда требуется определить, насколько правильно модель работает на данных, разделенных на две части. Кросс-валидация позволяет определить, насколько правильно модель работает на тестовой выборке, а не на тренировочной.\n",
            "\n",
            "Кросс-валидация используется в моделировании данных, когда требуется определить, насколько правильно модель работает на данных, разделенных на две части. Кросс-валидация позволяет определить, насколько правильно модель работает на тестовой выборке, а не на тренировочной.\n",
            "\n",
            "Кросс-валидация используется в моделировании данных, когда требуется определить, насколько правильно модель работает на данных, разделенных на две части. Кросс-валидация позволяет определить, насколько правильно модель работает на тестовой выборке, а не на тренировочной.\n",
            "\n",
            "Кросс-валидация используется в моделировании данных, когда требуется определить, насколько правильно модель работает на данных, разделенных на две части. Кросс-валидация позволяет определить, насколько правильно модель работает на тестовой выборке, а не на тренировочной.\n",
            "\n",
            "Кросс-валидация используется в моделировании данных, когда требуется определить, насколько правильно модель работает на данных, разделенных на две части. Кросс-валидация позволяет определить, насколько правильно мо\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №13"
      ],
      "metadata": {
        "id": "KYfBeqeDnU5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Какие есть способы оптимизации гиперпараметров?\"\n",
        "answer = rag.answer_with_rag(question)\n",
        "print(f\"\\n\\nВопрос: {question}\\n\\n\")\n",
        "print(f\"Информация из векторной базы данных: {answer[1]}\\n\\n\")\n",
        "print(f\"Ответ модели с RAG: {answer[0]}\\n\\n\")\n",
        "print(f\"Ответ модели без RAG: {rag.answer_without_rag(question)}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rax8oDdWnU5W",
        "outputId": "d30419a1-e7da-4164-a7f6-4a00a31cce39"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Вопрос: Какие есть способы оптимизации гиперпараметров?\n",
            "\n",
            "\n",
            "Информация из векторной базы данных: [{'score': 0.7513921441506308, 'text': 'Подбор гиперпараметров тоже можно сформулировать в виде задачи, которая может решаться с помощью байесовской оптимизации. Пусть, например, наша функция — значение валидационных метрик в зависимости от текущего сочетания гиперпараметров. Её вычисление затратно по времени (нужно натренировать и провалидировать модель), и мы не можем вычислить градиенты этой функции по её переменным (нашим гиперпараметрам).\\nБайесовская оптимизация имеет две основные компоненты:', 'article': 'Подбор гиперпараметров', 'segment_num': 26}, {'score': 0.7165964741635888, 'text': 'Самый естественный способ организовать перебор наборов гиперпараметров — сделать перебор по сетке (Grid Search):\\nдля каждого гиперпараметра фиксируется несколько значений;\\nперебираются все комбинации значений различных гиперпараметров, на каждой из этих комбинаций модель обучается и тестируется;\\nвыбирается комбинация, на которой модель показывает лучшее качество.\\nПримеры:', 'article': 'Подбор гиперпараметров', 'segment_num': 8}, {'score': 0.708133886921071, 'text': 'может моделировать внутренние зависимости между гиперпараметрами (за счёт работы с ними в едином подмножестве, где— число гиперпараметров);\\nможет расширять заданные изначально границы множества поиска гиперпараметров;\\nдостигает более высокого качества, чем Random Search, если удалось провести достаточное количество итераций.', 'article': 'Подбор гиперпараметров', 'segment_num': 80}]\n",
            "\n",
            "\n",
            "Ответ модели с RAG: 1. Grid Search: This is the most common approach for hyperparameter optimization. It involves searching over a set of hyperparameters and selecting the best combination of parameters.\n",
            "\n",
            "2. Bayesian Optimization: This is a probabilistic approach that uses Bayesian optimization to find the best combination of hyperparameters. It uses a probabilistic model to predict the performance of the model under different combinations of hyperparameters.\n",
            "\n",
            "3. Random Search: This is a simple approach that randomly selects a set of hyperparameters and tries to find the best combination.\n",
            "\n",
            "4. Bayesian Deep Learning: This is a Bayesian optimization approach that uses deep learning models to optimize hyperparameters. It uses a probabilistic model to predict the performance of the model under different combinations of hyperparameters.\n",
            "\n",
            "5. Hyperband: This is a hybrid approach that combines the best of both Grid Search and Bayesian Optimization. It uses a combination of Grid Search and Bayesian Optimization to find the best combination of hyperparameters.\n",
            "\n",
            "6. HyperTune: This is a Python library that provides a set of tools for hyperparameter optimization. It includes a grid search, bayesian optimization, and random search algorithms.\n",
            "\n",
            "7. Hyperopt: This is a Python library that provides a high-level interface for Bayesian optimization. It includes a grid search, bayesian optimization, and random search algorithms.\n",
            "\n",
            "8. AutoML: This is an automated machine learning approach that uses machine learning algorithms to optimize hyperparameters. It includes a grid search, bayesian optimization, and random search algorithms.\n",
            "\n",
            "9. XGBoost: This is a popular Python library for deep learning that includes a grid search, bayesian optimization, and random search algorithms.\n",
            "\n",
            "10. TensorFlow Optimizer: This is a TensorFlow library that provides a set of tools for hyperparameter optimization. It includes a grid search, bayesian optimization, and random search algorithms.\n",
            "\n",
            "\n",
            "Ответ модели без RAG: 1. Hyperparameter tuning: This involves optimizing the hyperparameters (e.g., learning rate, batch size, regularization strength) to achieve better performance on the training data.\n",
            "\n",
            "2. Grid search: This involves searching a grid of hyperparameters to find the best combination that achieves the desired performance.\n",
            "\n",
            "3. Early stopping: This involves stopping the training process once a certain metric (e.g., validation loss) stops improving.\n",
            "\n",
            "4. Hyperband: This is a hybrid algorithm that combines the advantages of grid search and early stopping. It uses a random search to find the best combination of hyperparameters, and then uses a simple stopping criterion to terminate the search.\n",
            "\n",
            "5. Random search: This involves randomly selecting a subset of hyperparameters and evaluating the model on the remaining subset. The model is then retrained on the remaining subset and evaluated again.\n",
            "\n",
            "6. Bayesian optimization: This involves using a probabilistic approach to optimize the hyperparameters. The model is trained on a dataset and the hyperparameters are optimized using a probabilistic approach that takes into account the uncertainty in the model's performance.\n",
            "\n",
            "7. Hyperparameter optimization frameworks: There are several hyperparameter optimization frameworks available, such as Hyperopt, Tune, and Optuna. These frameworks provide a user-friendly interface for optimizing hyperparameters and can handle large datasets.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №14"
      ],
      "metadata": {
        "id": "8fWoZ3uHnVBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Как работает алгоритм k-ближайших соседей?\"\n",
        "answer = rag.answer_with_rag(question)\n",
        "print(f\"\\n\\nВопрос: {question}\\n\\n\")\n",
        "print(f\"Информация из векторной базы данных: {answer[1]}\\n\\n\")\n",
        "print(f\"Ответ модели с RAG: {answer[0]}\\n\\n\")\n",
        "print(f\"Ответ модели без RAG: {rag.answer_without_rag(question)}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds2ZVwZdnVBO",
        "outputId": "80d00594-250f-4272-b9ff-148009a849b5"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Вопрос: Как работает алгоритм k-ближайших соседей?\n",
            "\n",
            "\n",
            "Информация из векторной базы данных: [{'score': 0.6919798215059092, 'text': 'В первой части параграфа мы расскажем об одном из самых известных метрических алгоритмов — методеk-ближайших соседей(k-nearest neighbors, KNN). Этот подход в основном чисто инженерный из-за отсутствия фазы обучения — в настоящее время уже почти нигде не применяется. Однако многие техники, на которых основан алгоритм, используются и в других методах.', 'article': 'Метрические методы', 'segment_num': 3}, {'score': 0.6919722878195854, 'text': 'Поиск ближайших соседей\\n========================================\\nДля того чтобы применять метод ближайших соседей, нужно уметь как-то находить этих самых соседей. С первого взгляда может показаться, что никакой проблемы нет: действительно, можно ведь просто перебрать все объекты из обучающей выборки, посчитать для каждого из них расстояние до тестового объекта и затем найти минимум.', 'article': 'Метрические методы', 'segment_num': 34}, {'score': 0.6919499375558125, 'text': 'Для метрических методов очень важно уметь эффективно находить ближайшие объекты, поэтому задача их поиска неизбежно возникает при применении любого такого алгоритма. Поэтому во второй части параграфа мы рассмотрим возможные подходы к быстрому поиску ближайших соседей.\\nМетод k-ближайших соседей (KNN)\\n========================================\\nПредставим, что мы проводим классификацию объектов на два класса — красный или жёлтый. Нам дана некоторая обучающая выборка и целевой объект (серый):', 'article': 'Метрические методы', 'segment_num': 5}]\n",
            "\n",
            "\n",
            "Ответ модели с RAG: K-ближайших соседей (KNN) - это метод ближайших соседей, который используется для классификации объектов на двух классах. Он основан на том, что для каждого объекта из обучающей выборки есть некоторая ближайшая к нему объект из тестовой выборки. Для этого алгоритм использует предоставленный контекст, который позволяет определить ближайший объект из тестовой выборки для каждого объекта из обучающей выборки.\n",
            "\n",
            "Для того чтобы найти ближайшие объекты, алгоритм KNN использует матрицу расстояний между объектами из обучающей выборки и тестовой выборки. В каждой строке матрицы расстояний указывается расстояние между объектами из обучающей выборки и тестовой выборки. В каждой столбце матрицы расстояний указывается расстояние между объектами из обучающей выборки и тестовой выборки.\n",
            "\n",
            "Для каждого объекта из обучающей выборки, алгоритм KNN определяет ближайший объект из тестовой выборки, который имеет наименьшее расстояние к этому объекту из обучающей выборки. Этот объект является ближайшим соседом этого объекта из обучающей выборки.\n",
            "\n",
            "Поиск ближайших соседей в KNN осуществляется в два этапа:\n",
            "\n",
            "1. Выборка: Алгоритм KNN выбирает обучающую выборку, которая содержит объекты, которые будут использоваться для обучения.\n",
            "\n",
            "2. Поиск ближайших соседей: Алгоритм KNN использует матрицу расстояний между объектами из обучающей выборки и тестовой выборки, чтобы найти ближайшие объекты.\n",
            "\n",
            "3. Выборка: Алгоритм KNN выбирает тестовой выборку, которая содержит объекты, которые будут использоваться для обучения.\n",
            "\n",
            "4\n",
            "\n",
            "\n",
            "Ответ модели без RAG: The k-nearest neighbors (k-NN) algorithm is a machine learning algorithm that finds the k most similar or nearest neighbors of a given input point in a dataset. The algorithm works by finding the k nearest neighbors of a given input point using a distance metric, such as Euclidean distance or Manhattan distance.\n",
            "\n",
            "Here's how the algorithm works:\n",
            "\n",
            "1. Define a distance metric: The algorithm uses a distance metric to compare the distance between each input point and the k nearest neighbors. The most common distance metric used in k-NN is Euclidean distance, which measures the distance between two points as the square root of the sum of the squares of the differences between their coordinates.\n",
            "\n",
            "2. Calculate the distance matrix: The algorithm calculates a distance matrix, which is a matrix of distances between each input point and its k nearest neighbors. The distance matrix is a square matrix with k rows and k columns, where each element in the matrix represents the distance between the input point and its k nearest neighbors.\n",
            "\n",
            "3. Find the k nearest neighbors: The algorithm finds the k nearest neighbors of each input point using a greedy algorithm. The algorithm starts with the input point and its closest k neighbors, and then selects the next closest neighbor based on the distance between the current neighbor and the input point. This process continues until all k nearest neighbors have been found.\n",
            "\n",
            "4. Calculate the similarity score: The algorithm calculates the similarity score between each input point and its k nearest neighbors by comparing the distance between the input point and its k nearest neighbors. The similarity score is calculated as the ratio of the distance between the input point and its k nearest neighbors to the distance between the input point and its nearest neighbor.\n",
            "\n",
            "5. Output the results: The algorithm outputs the k nearest neighbors of each input point, along with their similarity scores. The output can be in any format, such as a list of tuples or a dictionary.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №15"
      ],
      "metadata": {
        "id": "UQ--QdOhnVIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Что такое матрица ошибок?\"\n",
        "answer = rag.answer_with_rag(question)\n",
        "print(f\"\\n\\nВопрос: {question}\\n\\n\")\n",
        "print(f\"Информация из векторной базы данных: {answer[1]}\\n\\n\")\n",
        "print(f\"Ответ модели с RAG: {answer[0]}\\n\\n\")\n",
        "print(f\"Ответ модели без RAG: {rag.answer_without_rag(question)}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObTIapoJnVIR",
        "outputId": "f6911ee2-0eaf-464b-aa8c-bad733acd9cd"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Вопрос: Что такое матрица ошибок?\n",
            "\n",
            "\n",
            "Информация из векторной базы данных: [{'score': 0.6718861867535283, 'text': 'Вывод: матрица, ортонормированная по столбцам, отвечает датасету, в котором признаки не коррелированы и имеют единичную дисперсию\\nСингулярное разложение\\n========================================', 'article': 'Матричная факторизация', 'segment_num': 18}, {'score': 0.6572008316798352, 'text': 'Весь набор ошибок на отложенной выборке может служить аналогом матрицы ошибок из задачи классификации. А именно, когда мы рассматриваем две разные модели, то, глядя на то, как и на каких объектах они ошиблись, мы можем прийти к выводу, что для решения бизнес-задачи нам выгоднее взять ту или иную модель. И, аналогично со случаем бинарной классификации, мы можем начать строить агрегаты от вектора ошибок, получая тем самым разные метрики.\\nMSE, RMSE,\\n========================================', 'article': 'Метрики классификации и регрессии', 'segment_num': 81}, {'score': 0.6448831808483688, 'text': 'Если классов становится больше двух, расчёт метрик усложняется. Если задача классификации наклассов ставится какзадач об отделении классаот остальных (), то для каждой из них можно посчитать свою матрицу ошибок. Затем есть два варианта получения итогового значения метрики изматриц ошибок:\\nУсредняем элементы матрицы ошибок (TP, FP, TN, FN) между бинарными классификаторами, например. Затем по одной усреднённой матрице ошибок считаем Precision, Recall, F-меру. Это называютмикроусреднением.', 'article': 'Метрики классификации и регрессии', 'segment_num': 61}]\n",
            "\n",
            "\n",
            "Ответ модели с RAG: Матрица ошибок (Error Matrix) - это матрица, в которой каждый столбец содержит ошибки (удаленные объекты) в отложенной выборке, а каждый столбец вторым столбцом содержит ошибки (властительные объекты) в отложенной выборке. Ошибки в матрице ошибок являются результатом некоррелированности признаков в данных, которые не являются коррелированными.\n",
            "\n",
            "Матрица ошибок используется в задачах классификации, в которых используются две или более классы. В случае классификации наклассов, матрица ошибок используется для получения метрик, которые помогают определить, какой класс объект относится к.\n",
            "\n",
            "Примеры использования матрицы ошибок в задачах классификации:\n",
            "- В задаче классификации наклассов, когда используется матрица ошибок для получения метрик, например, для определения качества классификатора.\n",
            "- В задаче классификации наклассов, когда используется матрица ошибок для получения метрик, например, для определения качества модели.\n",
            "- В задаче классификации наклассов, когда используется матрица ошибок для получения метрик, например, для определения качества модели.\n",
            "\n",
            "Примеры использования матрицы ошибок в задачах машинного обучения:\n",
            "- В задаче классификации, когда используется матрица ошибок для получения метрик, например, для определения качества модели.\n",
            "- В задаче регрессии, когда используется матрица ошибок для получения метрик, например, для определения качества модели.\n",
            "- В задаче классификации, когда используется матрица ошибок для получения метрик, например, для определения качества модели.\n",
            "\n",
            "Примеры использования матрицы ошибо\n",
            "\n",
            "\n",
            "Ответ модели без RAG: Матрица ошибок (error matrix) в информатике и компьютерной технике является матрицей, которая содержит информацию о различных ошибках, которые могут возникать при выполнении задач или операций. Ошибки могут быть различными типами, такими как ошибки в алгоритмах, ошибки в программах, ошибки в вычислительных системах, ошибки в электронике, ошибки в электронике и др. Матрица ошибок используется для оценки качества результатов, а также для определения причин и решений для ошибок.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №16"
      ],
      "metadata": {
        "id": "RSLOpBRtnVRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Что такое графовая нейронная сеть?\"\n",
        "answer = rag.answer_with_rag(question)\n",
        "print(f\"\\n\\nВопрос: {question}\\n\\n\")\n",
        "print(f\"Информация из векторной базы данных: {answer[1]}\\n\\n\")\n",
        "print(f\"Ответ модели с RAG: {answer[0]}\\n\\n\")\n",
        "print(f\"Ответ модели без RAG: {rag.answer_without_rag(question)}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIfhhk80nVRJ",
        "outputId": "adc2dd7f-d10d-4a58-d22b-8d134657d6d2"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Вопрос: Что такое графовая нейронная сеть?\n",
            "\n",
            "\n",
            "Информация из векторной базы данных: [{'score': 0.8329692450605349, 'text': 'Как говорилось ранее, графовые нейронные сети являются обобщением сверточных. Если представить пиксели изображения вершинами графа, соединить соседние по свертке пиксели ребрами и предоставить относительную позицию пикселей в информации о ребре, то графовая свертка на таком графе будет работать так же, как и свертка над изображением.', 'article': 'Графовые нейронные сети', 'segment_num': 17}, {'score': 0.8019747025591457, 'text': 'Однако, сама суть работы у графовых и сверточных сетей совпадает. В графовой нейронной сети по очереди применяются слои, которые собирают информацию с соседей  и обновляют информацию в вершине. То же самое делают и обычные свертки. Поэтому такие слои и называютсяграфовыми свертками. Графовая свертка принимает на вход граф со скрытыми состояниями у вершин и ребер и выдает тот же граф, но уже с обновленными более информативными скрытыми состояниями.', 'article': 'Графовые нейронные сети', 'segment_num': 13}, {'score': 0.7731522568206264, 'text': 'На вход графовой нейронной сети подается граф. В отличие от сверточных нейронных сетей, которые требуют, чтобы все картинки в батче были одинакового размера, графовые нейронные сети допускают разные размеры у объектов батча. Кроме того, в отличие от картинок, у которых информация довольно однородна (это, как правило, несколько цветовых каналов) и хранится в пикселях, у графов информация может также храниться в вершинах и/или ребрах. Причем в одних задачах информация может быть только в вершинах, в других только в ребрах, а в третьих и там, и там. Сама информация может быть довольно разнородной: это могут быть и вещественные значения, и дискретные значения, в зависимости от природы графа и от типа решаемой задачи. Поэтому, довольно часто первым слоем в графовых нейронных сетях идут Embedding слои, которые переводят дискретные токены в вещественные векторы.', 'article': 'Графовые нейронные сети', 'segment_num': 12}]\n",
            "\n",
            "\n",
            "Ответ модели с RAG: Graph-based neural networks (GNNs) are a type of neural network that are designed to process data in a graph-like structure. In a graph, each node (vertex) represents a data point, and each edge (edge) represents a relationship between the data points. GNNs are a type of neural network that can be used to process data in a graph-like structure.\n",
            "\n",
            "In a GNN, nodes are represented as nodes in a graph, and edges are represented as edges between nodes. The nodes can be represented as features, and the edges can be represented as connections between the nodes. The GNN can be used to process data in a graph-like structure by processing the graph as a whole, rather than processing each node separately.\n",
            "\n",
            "Graph-based neural networks are often used in applications such as social network analysis, drug discovery, and recommendation systems. They have been shown to be effective in these applications due to their ability to process data in a graph-like structure.\n",
            "\n",
            "\n",
            "Ответ модели без RAG: Graphical Neural Networks (GNNs) es una técnica de aprendizaje automático que utiliza gráficos para representar la relación entre los datos. En GNNs, los datos se representan como gráficos, y los nodos (verdadero o falsos) se representan como vertices (verdadero o falsos) y las aristas (relaciones) se representan como edges (relaciones).\n",
            "\n",
            "En GNNs, las redes neuronales se utilizan para representar la relación entre los datos. Las redes neuronales se basan en la idea de que las neuronas se pueden considerar como neuronas de entrada, neuronas de salida y neuronas intermedias. Las neuronas de entrada reciben datos y las neuronas de salida producen resultados. Las neuronas intermedias se utilizan para representar la relación entre los datos.\n",
            "\n",
            "En GNNs, las redes neuronales se utilizan para representar la relación entre los datos. Las redes neuronales se basan en la idea de que las neuronas se pueden considerar como neuronas de entrada, neuronas de salida y neuronas intermedias. Las neuronas de entrada reciben datos y las neuronas de salida producen resultados. Las neuronas intermedias se utilizan para representar la relación entre los datos.\n",
            "\n",
            "En GNNs, las redes neuronales se utilizan para representar la relación entre los datos. Las redes neuronales se basan en la idea de que las neuronas se pueden considerar como neuronas de entrada, neuronas de salida y neuronas intermedias. Las neuronas de entrada reciben datos y las neuronas de salida producen resultados. Las neuronas intermedias se utilizan para representar la relación entre los datos.\n",
            "\n",
            "En GNNs, las redes neuronales se utilizan para representar la relación entre los datos. Las redes neuronales se basan en la idea de que las neuronas se pueden considerar como neuronas de entrada, neuronas de salida y neuronas intermedias. Las neuronas de entrada reciben datos y las neuronas de salida producen resultados. Las neuronas intermedias\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №17"
      ],
      "metadata": {
        "id": "Sw1i0jw2nVXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Что такое иерархическая кластеризация?\"\n",
        "answer = rag.answer_with_rag(question)\n",
        "print(f\"\\n\\nВопрос: {question}\\n\\n\")\n",
        "print(f\"Информация из векторной базы данных: {answer[1]}\\n\\n\")\n",
        "print(f\"Ответ модели с RAG: {answer[0]}\\n\\n\")\n",
        "print(f\"Ответ модели без RAG: {rag.answer_without_rag(question)}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUK4cuDgnVXi",
        "outputId": "ae00c2a2-18c5-4a13-d63b-dcacb181af40"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Вопрос: Что такое иерархическая кластеризация?\n",
            "\n",
            "\n",
            "Информация из векторной базы данных: [{'score': 0.863767445907889, 'text': 'Иерархическая агломеративная кластеризация\\n========================================\\nДругой классический метод кластеризации — этоиерархическая кластеризация. Иногда дополнительно уточняют:иерархическая агломеративная кластеризация. Название указывает сразу на два обстоятельства.', 'article': 'Кластеризация', 'segment_num': 35}, {'score': 0.8114915762617518, 'text': 'Во-вторых, кластеризация бывает, по аналогии с оргструктурой в организациях, плоской (когда все кластеры равноправны и находятся на одном уровне кластеризации) и иерархической (когда кластеры бывают вложены друг в друга и образуют древовидную структуру).', 'article': 'Кластеризация', 'segment_num': 37}, {'score': 0.7985560043884936, 'text': 'В случае иерархической агломеративной кластеризации мы действительно будем начинать с кластеров из одного объекта, постепенно объединяя их, а уже последовательность этих объединений даст структуру вложенности кластеров. Даже если в итоге мы будем использовать кластеры с одного уровня, не углубляясь ни в какую вложенность, кластеризация всё равно называется иерархической, так как иерархия естественным образом возникает в процессе работы алгоритма.\\nСам алгоритм выглядит предельно просто:', 'article': 'Кластеризация', 'segment_num': 38}]\n",
            "\n",
            "\n",
            "Ответ модели с RAG: Иерархическая кластеризация (или иерархическая агломеративная кластеризация) - это метод кластеризации, в котором кластеры кластера из одного объекта объединяются последовательно, а уже последовательность этих объединений даёт структуру вложенности кластеров. В иерархической кластеризации используется иерархия, которая может быть вложенной в иерархию.\n",
            "\n",
            "Иерархическая кластеризация имеет два основных принципа:\n",
            "\n",
            "1. Иерархия - кластеры кластера из одного объекта объединяются последовательно, а уже последовательность этих объединений даёт структуру вложенности кластеров.\n",
            "\n",
            "2. Вложенность - кластеры с одного уровня, не углубляясь ни в какую вложенность, называются иерархией.\n",
            "\n",
            "Иерархическая кластеризация используется в многомерных и многомерных кластеризациях, где кластеры из одного объекта объединяются последовательно, а уже последовательность этих объединений даёт структуру вложенности кластеров.\n",
            "\n",
            "\n",
            "Ответ модели без RAG: Иерархическая кластеризация (Hierarchical Clustering) — это метод кластеризации, в котором разделяются данные на группы, которые соответствуют определенным категориям или классам. В данном случае, категории могут быть разделены на уровни, например, на уровень города, на уровень района, на уровень улицы, на уровень домов, и т. д.\n",
            "\n",
            "Иерархическая кластеризация используется в разных областях, в том числе в сфере маркетинга, в области анализа данных, в области моделирования и в области анализа социальных сеть.\n",
            "\n",
            "Примеры применения иерархической кластеризации:\n",
            "\n",
            "1. Маркетинг: Иерархическая кластеризация используется для классификации клиентов по их потребностям и предпочтениям.\n",
            "\n",
            "2. Анализ данных: Иерархическая кластеризация используется для классификации данных по их категориям, например, по клиентам, по продуктам, по регионам, по времени, и т. д.\n",
            "\n",
            "3. Моделирование: Иерархическая кластеризация используется для классификации данных по их категориям, например, по клиентам, по продуктам, по регионам, по времени, и т. д.\n",
            "\n",
            "4. Анализа социальных сеть: Иерархическая кластеризация используется для классификации пользователей по их социальным сетям, например, по группам, по городам, по регионам, и т. д.\n",
            "\n",
            "5. Анализ социальных сеть: Иерархическая кластеризация используется для классификации пользователей по их социальным сетям, например, по группам, по городам, по регионам, и т. д.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №18"
      ],
      "metadata": {
        "id": "2-h_5bcdnVgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Что такое коэффициент силуэта?\"\n",
        "answer = rag.answer_with_rag(question)\n",
        "print(f\"\\n\\nВопрос: {question}\\n\\n\")\n",
        "print(f\"Информация из векторной базы данных: {answer[1]}\\n\\n\")\n",
        "print(f\"Ответ модели с RAG: {answer[0]}\\n\\n\")\n",
        "print(f\"Ответ модели без RAG: {rag.answer_without_rag(question)}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBAQ9T4NnVgL",
        "outputId": "dcfaa6e7-e894-4c3d-d0e8-3d4a439c8516"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Вопрос: Что такое коэффициент силуэта?\n",
            "\n",
            "\n",
            "Информация из векторной базы данных: [{'score': 0.541811234130438, 'text': 'Чтобы ввести коэффициент силуэта, нам потребуются две вспомогательные величины. Первая,, — это среднее расстояние междуи объектами того же кластера. Вторая,, — это среднее расстояние междуи объектами следующего ближайшего кластера. Коэффициент силуэта вводится следующим образом:', 'article': 'Кластеризация', 'segment_num': 63}, {'score': 0.5255612946413701, 'text': 'где– это дисперсия стохградиента, а– константа сильной выпуклости, показывающая, насколько функция является «не плоской» в окрестности точки оптимума. Доказательство в том жепрепринте С. Стича.\\nМораль в следующем: дисперсия стохастического градиента, вычисленного по батчу размераравна, где– это дисперсия одного градиента. То есть увеличение размера батча помогает и с теоретической точки зрения.', 'article': 'Оптимизация в ML', 'segment_num': 39}, {'score': 0.5251804141042365, 'text': 'Слабости метода Ньютона\\n========================================', 'article': 'Методы второго порядка', 'segment_num': 11}]\n",
            "\n",
            "\n",
            "Ответ модели с RAG: Коэффициент силуэта (Squared Euclidean Distance) в математике является функцией расстояния между двумя объектами в рассматриваемом контексте. Он используется в машинном обучении для определения близости двух объектов в контексте кластеризации. Коэффициент силуэта вводится следующим образом:\n",
            "\n",
            "given:\n",
            "\n",
            "x1 = (x11, x12, ..., x1n)\n",
            "x2 = (x21, x22, ..., x2n)\n",
            "\n",
            "where:\n",
            "\n",
            "x11, x12, ..., x1n - first n coordinates of x1\n",
            "x21, x22, ..., x2n - first n coordinates of x2\n",
            "\n",
            "given:\n",
            "\n",
            "distance = sqrt(sum((x11 - x21) ** 2 + (x12 - x22) ** 2 + ... + (x1n - x2n) ** 2))\n",
            "\n",
            "where:\n",
            "\n",
            "sum - sum of squared differences between x11, x12, ..., x1n and x21, x22, ..., x2n\n",
            "\n",
            "коэффициент силуэта является функцией расстояния между двумя объектами в рассматриваемом контексте. Он используется для определения близости двух объектов в контексте кластеризации. Коэффициент силуэта вводится следующим образом:\n",
            "\n",
            "given:\n",
            "\n",
            "x1 = (x11, x12, ..., x1n)\n",
            "x2 = (x21, x22, ..., x2n)\n",
            "\n",
            "where:\n",
            "\n",
            "x11, x12, ..., x1n - first n coordinates of x1\n",
            "x21, x22, ..., x2n - first n coordinates of x2\n",
            "\n",
            "given:\n",
            "\n",
            "distance = sqrt(sum((x11 - x21) ** 2 + (x12 - x22) ** 2 + ... + (x1n - x2n) ** 2))\n",
            "\n",
            "where:\n",
            "\n",
            "sum - sum of squared differences between x11\n",
            "\n",
            "\n",
            "Ответ модели без RAG: El coeficiente de fuerza es una medida de la fuerza que un objeto puede producir en un medio de trabajo. El coeficiente de fuerza es una medida de la capacidad de un objeto de producir fuerza en un medio de trabajo. El coeficiente de fuerza es una medida de la capacidad de un objeto de producir fuerza en un medio de trabajo.\n",
            "\n",
            "En el contexto de la ingeniería mecánica, el coeficiente de fuerza es una medida de la capacidad de un objeto de producir fuerza en un medio de trabajo. El coeficiente de fuerza es una medida de la capacidad de un objeto de producir fuerza en un medio de trabajo. El coeficiente de fuerza es una medida de la capacidad de un objeto de producir fuerza en un medio de trabajo.\n",
            "\n",
            "En el contexto de la ingeniería mecánica, el coeficiente de fuerza es una medida de la capacidad de un objeto de producir fuerza en un medio de trabajo. El coeficiente de fuerza es una medida de la capacidad de un objeto de producir fuerza en un medio de trabajo. El coeficiente de fuerza es una medida de la capacidad de un objeto de producir fuerza en un medio de trabajo.\n",
            "\n",
            "En el contexto de la ingeniería mecánica, el coeficiente de fuerza es una medida de la capacidad de un objeto de producir fuerza en un medio de trabajo. El coeficiente de fuerza es una medida de la capacidad de un objeto de producir fuerza en un medio de trabajo. El coeficiente de fuerza es una medida de la capacidad de un objeto de producir fuerza en un medio de trabajo.\n",
            "\n",
            "En el contexto de la ingeniería mecánica, el coeficiente de fuerza es una medida de la capacidad de un objeto de producir fuerza en un medio de trabajo. El coeficiente de fuerza es una medida de la capacidad de un objeto de producir fuerza en un medio de trabajo. El coeficiente de fuerza es una medida de la capacidad\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №19"
      ],
      "metadata": {
        "id": "ZMJXkraynVn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Что такое энтропия?\"\n",
        "answer = rag.answer_with_rag(question)\n",
        "print(f\"\\n\\nВопрос: {question}\\n\\n\")\n",
        "print(f\"Информация из векторной базы данных: {answer[1]}\\n\\n\")\n",
        "print(f\"Ответ модели с RAG: {answer[0]}\\n\\n\")\n",
        "print(f\"Ответ модели без RAG: {rag.answer_without_rag(question)}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkUuJhUrnVn2",
        "outputId": "52d8d77b-4871-49d0-8cee-8e25b1cd9871"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Вопрос: Что такое энтропия?\n",
            "\n",
            "\n",
            "Информация из векторной базы данных: [{'score': 0.7349346983672955, 'text': 'Кстати, Шеннон изначально собирался назвать информационную энтропию или «информацией», или «неопределённостью», но в итоге выбрал название «энтропия», потому что концепция со схожим смыслом в статистической механике уже была названа энтропией. Употребление термина из другой научной области выглядело убедительным преимуществом при ведении научных споров.\\nИнформативность в задаче классификации: критерий Джини\\n========================================', 'article': 'Решающие деревья', 'segment_num': 46}, {'score': 0.7303112958867513, 'text': 'Вот мы и вывели формулу энтропии!\\nПример 2. Энтропия нормального распределенияравна, и чем меньше дисперсия, тем меньше энтропия, что и логично: ведь когда дисперсия мала, значения сосредоточены возле матожидания, и они становятся менее «разнообразными».\\nЭнтропия тесно связана с другим важным понятием из теории информации —дивергенцией Кульбака-Лейблера. Она определяется длякак\\nв непрерывном случае и точно так же, но только с суммой вместо интеграла в дискретном.', 'article': 'Экспоненциальный класс распределений и принцип максимальной энтропии', 'segment_num': 9}, {'score': 0.6836581177622167, 'text': 'Вопрос на подумать. Итак, всякое распределение с носителемимеет энтропию не больше. А у какого распределения она в точности равна?\\nТакое произойдёт, если все вероятности,, т.е. распределение равномерное.\\nДифференциальная энтропия\\n========================================\\nЧтобы вычислить энтропию непрерывной случайной величины, надо, как водится, сумму заменить на интеграл, и получится формуладифференциальной энтропии:', 'article': 'Энтропия и семейство экспоненциальных распределений', 'segment_num': 8}]\n",
            "\n",
            "\n",
            "Ответ модели с RAG: Энтропия (англ. Entropy) - это математическое понятие, которое используется в теории информации и статистике. В информатике, энтропия - это величина, которая определяет вероятность того, что какая-либо информационная единица (например, символ, число, вероятность, вероятность распределения) будет распределена в некотором распределении. В статистике энтропия используется для оценки разницы между распределениями, которые принимают участие в анализе данных.\n",
            "\n",
            "В математике энтропия используется для оценки разницы между распределениями, которые принимают участие в анализе данных. В частности, энтропия используется для оценки разницы между распределениями вероятностей, которые принимают участие в анализе данных. В теории информации энтропия используется для оценки разницы между распределениями информации, которые принимают участие в анализе данных.\n",
            "\n",
            "В общем случае, энтропия определяется как сумма последовательности вероятностей, которые принимают участие в распределении. В случае распределения вероятностей, которые принимают участие в анализе данных, энтропия определяется как сумма последовательности вероятностей, которые принимают участие в распределении.\n",
            "\n",
            "Примеры распределений, которые принимают участие в анализе данных, включают в себя распределения вероятностей, которые принимают участие в анализе данных в области статистики, а также распределения вероятностей, которые принимают участие в анализе данных в области информатики.\n",
            "\n",
            "\n",
            "Ответ модели без RAG: Энтропия (от  — «внутренность, внутренний» и  — «отражение, изображение») — это физическая величина, которая определяет количество и тип энергии, выделяемой из системы вследствие изменения её состояния. Энтропия является одним из основных показателей статистической физики, а также взаимосвязанной с ним теории колебаний.\n",
            "\n",
            "Энтропия является одним из основных показателей статистической физики, а также взаимосвязанной с ним теории колебаний. В физике энтропия используется для описания состояния системы в зависимости от её состояния и для определения энергии системы в зависимости от её состояния. Энтропия также используется в других областях, таких как биология, химия, экономика и другие.\n",
            "\n",
            "Взаимосвязанная с ним теория колебаний — это теория, которая объясняет основные свойства и эффекты колебаний в системах, в которых присутствуют элементарные частицы. Энтропия является одним из основных показателей этой теории.\n",
            "\n",
            "Взаимосвязанная с ним теория колебаний используется для описания колебаний в системах, в которых присутствуют элементарные частицы. Энтропия является одним из основных показателей этой теории.\n",
            "\n",
            "Примеры применения энтропии в физике:\n",
            "\n",
            "1. Колебания в системах, в которых присутствуют элементарные частицы:\n",
            "\n",
            "- Колебания в системах, в которых присутствуют электроны: взаимосвязанная с ним теория колебаний используется для описания колебаний в системах, в которых присутствуют электроны.\n",
            "\n",
            "- Колебания в системах, в которых присутствуют протоны: взаимосвязанная с ним теория колебаний используется для описания колебаний\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопрос №20"
      ],
      "metadata": {
        "id": "HBk9CxrtnVvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Что такое MSE?\"\n",
        "answer = rag.answer_with_rag(question)\n",
        "print(f\"\\n\\nВопрос: {question}\\n\\n\")\n",
        "print(f\"Информация из векторной базы данных: {answer[1]}\\n\\n\")\n",
        "print(f\"Ответ модели с RAG: {answer[0]}\\n\\n\")\n",
        "print(f\"Ответ модели без RAG: {rag.answer_without_rag(question)}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07GQaMtnnVvK",
        "outputId": "53e2c8e3-6d0a-4fe4-a69e-e5553ea964dc"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-e65552691808>:43: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = self.client.search(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Вопрос: Что такое MSE?\n",
            "\n",
            "\n",
            "Информация из векторной базы данных: [{'score': 0.6897643678364391, 'text': 'MSE — одна из самых популярных метрик в задаче регрессии. Она уже знакома вам, так как применяется в качестве функции потерь (или входит в ее состав) во многих ранее рассмотренных методах.\\nИногда для того, чтобы показатель эффективности MSE имел размерность исходных данных, из него извлекают квадратный корень и получают показатель эффективности RMSE.', 'article': 'Метрики классификации и регрессии', 'segment_num': 82}, {'score': 0.6149995752401051, 'text': 'При фиксированной дисперсии и при предсказании шума с помощью взвешенной MSE. Или просто MSE.являетсясамым популярнымвариантом, который на практике дает лучшие результаты.\\nВыбор расписания\\n========================================\\nРасписание является гиперпараметром, основными требованиями на который являются невозрастаниеи чтобы прямой процесс сходился кв пределе по. Второе может гарантироваться тем, что. Вспомним,\\nОднако на практикеонотакже проверяется, чтобыбыло близко к 0.', 'article': 'Диффузионные модели', 'segment_num': 13}, {'score': 0.5653106522769442, 'text': 'То есть при жадной минимизации MSE информативность — это оценка дисперсии таргетов для объектов, попавших в лист. Получается очень стройная картинка: оценка значения в каждом листе — это среднее, а выбирать сплиты надо так, чтобы сумма дисперсий в листьях была как можно меньше.\\nИнформативность в задаче регрессии: MAE\\n========================================', 'article': 'Решающие деревья', 'segment_num': 34}]\n",
            "\n",
            "\n",
            "Ответ модели с RAG: MSE (Mean Squared Error) - это метрика потерь в регрессии, которая используется для оценки качества модели. Метрика MSE представляет собой квадратное отклонение исходных данных от предсказанных значений. Метрика MSE имеет размерность исходных данных, поэтому она применяется для расчета качества модели для каждого из исходных данных. Метрика MSE является одним из самых популярных метрик в задаче регрессии.\n",
            "\n",
            "\n",
            "Ответ модели без RAG: MSE, or Multivariate Student's Equation, is a statistical method used to analyze the relationship between multiple variables. It is a non-parametric method that is based on the principle of correlation, which measures the strength of the linear relationship between two or more variables. MSE is commonly used in data analysis and statistical modeling to identify the best linear unbiased estimator (BLUE) for a given set of data. MSE is also used in regression analysis to estimate the regression coefficients and to test the significance of the regression coefficients. MSE is a powerful tool for analyzing data and identifying the best model for a given set of data.\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}