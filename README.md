## Решённые задания с курса «Основы обучения больших языковых моделей», проводимого на ВМК МГУ преподавателем Тихомировым М. М.

### Задание 1. Основы LLM

Сравнение двух малых моделей (**Qwen2.5-3B-Instruct** и **Phi-4-mini-instruct**) по качеству генерации ответов на разные вопросы.
Вывод: Qwen даёт более креативные, но иногда нелогичные ответы, Phi — более нейтральные и структурированные.

### Задание 2. Генеративная бинарная классификация на основе фреймворка llmtf

Классификация «да/нет» на основе датасета **Russian SuperGLUE**. Сравнивались модели **RuadaptQwen2.5-1.5B** и **TinyLlama-1.1B**.
Вывод: TinyLlama показала выше точность (62%), но хуже справлялась с дисбалансом классов, тогда как RuadaptQwen2.5-1.5B распределяла ответы более сбалансированно.

### Задание 3. RAG-система

Создание Retrieval-Augmented Generation (RAG) с использованием Qdrant и моделей SmolLM2-135M и TinyLlama-1.1B.
Вывод: TinyLlama (1.1B) значительно превзошла SmolLM2 (135M) по метрикам ROUGE-L и BERTScore, что связано с большим количеством параметров и лучшей генерацией.

### Задание 5. RAG-система для учебника Яндекс по ML

Реализована полноценная RAG-система для учебника по машинному обучению с сайта Яндекс.Практикума (https://education.yandex.ru/handbook/ml).

* Парсинг статей с помощью BeautifulSoup.
* Разбиение на чанки по 512 символов.
* Векторная БД в Qdrant с эмбеддингами от `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`.
* Генерация ответов через TinyLlama-1.1B.

Вывод: RAG значительно улучшил качество ответов. Модель стала давать точные и специализированные объяснения (например, для ROC-кривой или градиентного бустинга), избегая типичных ошибок без RAG (галлюцинации, повторения, уход в другие области, случайные ответы на других языках).

